{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LangChain의 개념과 주요 컴포넌트 이해\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain이란 \n",
    "\n",
    "핵심 내용:\n",
    "- **LangChain**은 LLM 기반 애플리케이션 개발을 위한 프레임워크\n",
    "\n",
    "- **Chain**은 작업을 순차적으로 실행하는 파이프라인 구조를 제공\n",
    "\n",
    "- **Agent**는 자율적 의사결정이 가능한 실행 단위\n",
    "\n",
    "결론:\n",
    "- LangChain은 Chain과 Agent라는 두 가지 핵심 기능을 통해 LLM 애플리케이션 개발을 효율적으로 지원\n",
    "\n",
    "\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"https://python.langchain.com/svg/langchain_stack_112024_dark.svg\" \n",
    "            alt=\"langchain_stack\" \n",
    "            width=\"600\" \n",
    "            style=\"border: 0;\">\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain 컴포넌트 \n",
    "\n",
    "- LangChain **주요 컴포넌트**: LLM/ChatModel, Prompt, Memory, Tool, Document Loader, Text Splitter, Embedding, Vectorstore\n",
    "\n",
    "- **언어 처리 기능**은 LLM/ChatModel이 중심이 되며, Prompt와 Memory로 대화를 관리\n",
    "\n",
    "- **문서 처리와 검색**은 Document Loader, Text Splitter, Embedding, Vectorstore가 담당\n",
    "\n",
    "- **모듈성**이 핵심 특징으로, 독립적인 컴포넌트들을 조합해 RAG와 같은 복잡한 시스템을 구현 가능 \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경 변수 로드\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 모델 (Models)\n",
    "- LLM, ChatModel 등으로 구분\n",
    "- OpenAI, Anthropic, Google 등 다양한 모델을 지원\n",
    "- 텍스트 생성, 대화, 요약 등의 작업을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI 모델을 사용하여 대화 생성\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# 모델에 메시지를 보내고 응답을 받기\n",
    "response = model.invoke(\"안녕하세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 10, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-Bmx7eUUZDZBLr7QGu7rz7hKksO6TB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0a59ea6c-cf00-4ce6-9d50-31ee729aa61e-0', usage_metadata={'input_tokens': 10, 'output_tokens': 10, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 응답 객체(AIMessage): 메시지(content)와 메타데이터(response_metadata 등)를 포함\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변:  안녕하세요! 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "# 응답 객체의 메시지 내용 출력\n",
    "print(\"답변: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타데이터:  {'token_usage': {'completion_tokens': 10, 'prompt_tokens': 10, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-Bmx7eUUZDZBLr7QGu7rz7hKksO6TB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "# 응답 객체의 메타데이터 출력\n",
    "print(\"메타데이터: \", response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 메시지 (Messages)\n",
    "- Chat Model에서 사용할 수 있는 통합된 메시지 형식을 제공\n",
    "- 각 모델 제공자의 특정 메시지 형식을 신경 쓰지 않고도 다양한 채팅 모델을 활용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. HumanMessage`\n",
    "- 사용자 역할에 해당 (user, human 등)\n",
    "- 사용자의 입력을 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변:  \"Glory\"는 한국어로 보통 \"영광\" 또는 \"영예\"로 번역됩니다. 문맥에 따라 \"영광\", \"명예\", \"찬란함\" 등으로도 해석될 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 사용자 메시지 생성\n",
    "human_message = HumanMessage(content=\"Glory를 한국어로 번역해주세요.\")\n",
    "\n",
    "# 번역 요청 및 응답 받기\n",
    "response = model.invoke([human_message])  # 메시지 리스트로 전달\n",
    "\n",
    "# 답변 출력\n",
    "print(\"답변: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Glory\"는 한국어로 보통 \"영광\"이라고 번역합니다. 상황에 따라 \"명예,\" \"영예,\" 또는 \"찬란함\" 등으로도 번역될 수 있습니다. 필요에 따라 적절한 표현을 선택하시면 됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 17, 'total_tokens': 75, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlRG8Bpm4npLD7KiHQ38X0kN90F1E', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0b97e3b9-a3eb-4fc5-b0f2-9679f44280b9-0', usage_metadata={'input_tokens': 17, 'output_tokens': 58, 'total_tokens': 75, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자열을 입력하면, 자동으로 HumanMessage로 변환하여 요청\n",
    "model.invoke(\"Glory를 한국어로 번역해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. AIMessage`\n",
    "- AI 모델의 응답을 표현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Glory\"를 한국어로 번역하면 상황에 따라 여러 가지가 있을 수 있지만, 일반적으로는 다음과 같이 번역됩니다:\\n\\n1. 영광\\n2. 영예\\n3. 명예\\n4. 찬란함\\n\\n문맥에 맞게 적절한 단어를 선택하시면 됩니다. 도움이 필요하시면 문장 예시도 알려주세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 17, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlREznATRsfM6C5SBaJSj5B4wJqNR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f028acc0-2a85-487a-afa4-3650b9347b99-0', usage_metadata={'input_tokens': 17, 'output_tokens': 81, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI 모델의 응답 객체를 출력 \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Glory\"를 한국어로 번역하면 상황에 따라 여러 가지가 있을 수 있지만, 일반적으로는 다음과 같이 번역됩니다:\\n\\n1. 영광\\n2. 영예\\n3. 명예\\n4. 찬란함\\n\\n문맥에 맞게 적절한 단어를 선택하시면 됩니다. 도움이 필요하시면 문장 예시도 알려주세요!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 응답 텍스트 부분을 출력\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 17,\n",
       " 'output_tokens': 81,\n",
       " 'total_tokens': 98,\n",
       " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       " 'output_token_details': {'audio': 0, 'reasoning': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰 사용량 출력\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. SystemMessage`\n",
    "- 시스템 역할에 해당 (system, developer 등)\n",
    "- AI 모델의 동작과 제약사항을 정의하는데 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='당신은 영어를 한국어로 번역하는 AI 어시스턴트입니다.', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage \n",
    "\n",
    "# 시스템 메시지 생성\n",
    "system_msg = SystemMessage(content=\"당신은 영어를 한국어로 번역하는 AI 어시스턴트입니다.\")\n",
    "\n",
    "# 메시지 객체 확인\n",
    "system_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변:  영광\n"
     ]
    }
   ],
   "source": [
    "# 번역 요청 (HumanMessage)과 시스템 메시지(SystemMessage)를 함께 사용\n",
    "human_message = HumanMessage(content=\"Glory\")\n",
    "messages = [system_msg, human_message]\n",
    "\n",
    "# 모델에 메시지를 보내고 응답 받기\n",
    "response = model.invoke(messages)\n",
    "\n",
    "# 답변 출력\n",
    "print(\"답변: \", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 프롬프트 템플릿 (Prompt Template)\n",
    "- 프롬프트 템플릿을 통해 일관된 입력 형식을 제공\n",
    "    1. 사용자의 입력과 파라미터를 언어 모델이 이해할 수 있는 형태로 변환하는 도구\n",
    "    2. 언어 모델에게 전달할 지시문을 만드는 틀\n",
    "- 변수를 포함한 동적 프롬프트 생성이 가능\n",
    "    1. 모든 템플릿은 딕셔너리 형태의 입력을 받아서 처리\n",
    "    2. 출력은 PromptValue 형태로 반환되며, 이는 문자열이나 메시지 리스트로 변환 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. 문자열 프롬프트 템플릿 (String PromptTemplate)`\n",
    "- 가장 기본적인 형태\n",
    "- 단일 문자열을 형식화하는데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='고양이에 대한 이야기를 해줘')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 템플릿 생성 \n",
    "# \"{topic}에 대한 이야기를 해줘\"라는 템플릿을 사용하여\n",
    "# topic이라는 변수를 포함하는 프롬프트를 생성\n",
    "template = PromptTemplate.from_template(\"{topic}에 대한 이야기를 해줘\")\n",
    "\n",
    "# 템플릿 사용\n",
    "# \"고양이\"라는 주제를 사용하여 프롬프트 생성\n",
    "# invoke 메서드를 통해 템플릿에 값을 전달\n",
    "prompt = template.invoke({\"topic\": \"고양이\"})\n",
    "\n",
    "# 템플릿 출력\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. 채팅 프롬프트 템플릿 (ChatPromptTemplate)`\n",
    "- 여러 메시지를 포함하는 대화형 템플릿을 만들 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='당신은 도움이 되는 비서입니다', additional_kwargs={}, response_metadata={}), HumanMessage(content='인공지능에 대해 설명해주세요', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 채팅 템플릿 생성\n",
    "# 여기서는 시스템 메시지와 사용자 메시지를 포함하여 정의\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 도움이 되는 비서입니다\"),\n",
    "    (\"user\", \"{subject}에 대해 설명해주세요\")\n",
    "])\n",
    "\n",
    "# 템플릿 사용\n",
    "prompt = template.invoke({\"subject\": \"인공지능\"})\n",
    "\n",
    "# 출력\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. 메시지 플레이스홀더 (MessagesPlaceholder)`\n",
    "- 기존 메시지 목록을 템플릿의 특정 위치에 삽입할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 도움이 되는 비서입니다', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='안녕하세요! 제 이름은 스티브입니다.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='제 이름을 기억하나요?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 메시지 플레이스홀더가 있는 템플릿\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 도움이 되는 비서입니다\"),\n",
    "    MessagesPlaceholder(\"chat_history\")   # 채팅 기록을 플레이스홀더로 사용 (예: 이전 대화 내용) -> 이 위치에 메시지 목록을 추가할 수 있음\n",
    "])\n",
    "\n",
    "# 템플릿 사용\n",
    "prompt = template.invoke({\n",
    "    \"chat_history\": [\n",
    "        HumanMessage(content=\"안녕하세요! 제 이름은 스티브입니다.\"),\n",
    "        AIMessage(content=\"안녕하세요! 무엇을 도와드릴까요?\"),\n",
    "        HumanMessage(content=\"제 이름을 기억하나요?\")\n",
    "        ]\n",
    "})\n",
    "\n",
    "# 출력\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 출력 파서 (Output Parser)\n",
    "1. **역할과 기능**\n",
    "    - 모델의 텍스트 출력을 구조화된 데이터로 변환\n",
    "    - 채팅 모델과 LLM의 출력을 정규화\n",
    "    - 다운스트림 작업을 위한 데이터 형식 변환\n",
    "\n",
    "2. **사용 시 고려사항**\n",
    "    - OpenAI function calling과 같은 기능이 있는 경우, 해당 기능을 우선 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) StrOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울은 대한민국의 수도이자 최대 도시로서 다양한 특징을 가지고 있습니다. 주요 특징을 정리하면 다음과 같습니다:\n",
      "\n",
      "1. **정치·행정의 중심지**  \n",
      "   서울은 대한민국 정부의 중심지로 대통령 집무실인 청와대, 국회의사당, 중앙행정기관 등이 위치해 있습니다.\n",
      "\n",
      "2. **경제·금융의 중심**  \n",
      "   서울은 국내 경제 활동의 핵심지로, 많은 대기업 본사와 금융기관, 증권거래소가 모여 있습니다. 강남구, 종로구 등지에 주요 비즈니스 지구가 형성되어 있습니다.\n",
      "\n",
      "3. **문화와 역사**  \n",
      "   서울은 조선 시대의 궁궐(경복궁, 창덕궁 등), 한옥마을, 왕릉 등 역사적 유산들이 많이 보존되어 있으며, 동시에 현대적 문화 공간과 예술 공연장도 활발합니다.\n",
      "\n",
      "4. **교육의 중심지**  \n",
      "   서울에는 서울대학교, 연세대학교, 고려대학교 등 국내 최고의 대학들이 몰려 있어 교육과 연구의 중심지 역할을 합니다.\n",
      "\n",
      "5. **교통의 요지**  \n",
      "   지하철 1호선부터 9호선까지 매우 발달된 지하철망과 버스 시스템이 있고, 두 개의 국제공항(인천국제공항, 김포국제공항)과 고속도로가 연결되어 교통이 편리합니다.\n",
      "\n",
      "6. **다양한 생활 인프라**  \n",
      "   쇼핑, 음식, 엔터테인먼트 등 다양한 생활 편의 시설이 잘 갖춰져 있으며, 남대문시장, 동대문시장, 명동, 홍대 등 다양한 상업지역이 존재합니다.\n",
      "\n",
      "7. **인구 밀집**  \n",
      "   약 천만 명 이상의 인구가 거주하는 대도시로, 매우 높은 인구 밀도를 가지고 있습니다.\n",
      "\n",
      "8. **국제적 도시**  \n",
      "   다문화 사회로서 외국인 거주자도 많고, 국제회의, 행사 등이 자주 열려 글로벌 도시로 자리매김하고 있습니다.\n",
      "\n",
      "이 외에도 서울은 첨단 IT산업, 벤처기업, 스타트업의 중심지이기도 하며, 자연과 도시가 어우러진 한강공원 등 휴식 공간도 풍부합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 기본적인 문자열 파서 사용\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate.from_template(\"도시 {city}의 특징을 알려주세요\")\n",
    "\n",
    "# 모델 정의\n",
    "model = ChatOpenAI(model='gpt-4.1-mini')\n",
    "\n",
    "# 체인 구성\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# 체인 실행\n",
    "result = chain.invoke({\"city\": \"서울\"})\n",
    "\n",
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 구조화된 출력 (with_structured_output 메소드)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Pydantic 클래스로 출력 구조를 정의\n",
    "class CityInfo(BaseModel):\n",
    "    name: str = Field(description=\"도시 이름\")\n",
    "    description: str = Field(description=\"도시의 특징\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='서울' description='서울은 대한민국의 수도로, 경제, 문화, 정치의 중심지입니다. 한강을 중심으로 발전하였으며, 고궁과 현대적인 건축물이 조화를 이루고 있습니다. 다양한 문화 행사와 맛집, 쇼핑 지역이 많아 관광객들에게 인기 있는 도시입니다.'\n",
      "--------------------\n",
      "도시 이름: 서울\n",
      "특징: 서울은 대한민국의 수도로, 경제, 문화, 정치의 중심지입니다. 한강을 중심으로 발전하였으며, 고궁과 현대적인 건축물이 조화를 이루고 있습니다. 다양한 문화 행사와 맛집, 쇼핑 지역이 많아 관광객들에게 인기 있는 도시입니다.\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. 출력 스키마 정의\n",
    "class CityInfo(BaseModel):\n",
    "    name: str = Field(description=\"도시 이름\")\n",
    "    description: str = Field(description=\"도시의 특징\")\n",
    "\n",
    "# 2. 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate.from_template(\"도시 {city}의 특징을 알려주세요.\")\n",
    "\n",
    "# 3. 모델 생성 및 구조화된 출력 바인딩\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "structured_model = model.with_structured_output(CityInfo)\n",
    "\n",
    "# 4. 프롬프트와 모델 체인 연결\n",
    "chain = prompt | structured_model\n",
    "\n",
    "# 5. 체인 실행\n",
    "result = chain.invoke({\"city\": \"서울\"})\n",
    "\n",
    "# 6. 결과 출력 (CityInfo 객체)\n",
    "print(result)\n",
    "print(\"-\" * 20)\n",
    "print(f\"도시 이름: {result.name}\")\n",
    "print(f\"특징: {result.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 메모리 (Memory)\n",
    "- 대화 기록을 저장하고 관리\n",
    "- 컨텍스트 유지를 위한 다양한 메모리 타입을 제공\n",
    "- 대화 요약, 버퍼링 등의 기능을 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# 메모리 기반 히스토리 구현\n",
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    \"\"\"메모리 기반 채팅 메시지 히스토리\"\"\"\n",
    "\n",
    "    # 메시지 목록\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    \n",
    "    # 메시지 추가\n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        self.messages.extend(messages)\n",
    "    \n",
    "    # 메시지 목록 초기화 \n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "\n",
    "# 세션 저장소\n",
    "store = {}\n",
    "\n",
    "# 세션 ID로 히스토리 가져오기\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    \"\"\"세션 ID에 해당하는 채팅 메시지 히스토리를 반환합니다.\"\"\"\n",
    "\n",
    "    # 세션 ID가 저장소에 없으면 새 InMemoryHistory 객체 생성\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "        \n",
    "    # 해당 세션 ID의 히스토리 반환\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채팅 모델과 프롬프트 설정\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 {subject}에 능숙한 비서입니다\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | ChatOpenAI(model='gpt-4.1-mini')\n",
    "\n",
    "# 히스토리 관리 추가\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,    # 실행 체인\n",
    "    get_session_history,  # 세션 ID에 해당하는 히스토리 가져오는 함수\n",
    "    input_messages_key=\"question\",     # 입력 메시지 키\n",
    "    history_messages_key=\"history\"     # 히스토리 메시지 키\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1+2는 3입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 31, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BmynRtwDqtMqjU6mLiIaW9Wpp2Geg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--269f4a6d-6b3e-4ec2-882f-b5d418fcc79b-0' usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행\n",
    "response = chain_with_history.invoke(\n",
    "    {\"subject\": \"수학\", \"question\": \"1+2는 얼마인가요?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='1+2는 얼마인가요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='1+2는 3입니다. 도움이 필요하시면 언제든 말씀해 주세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 31, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlROtyecmNP9D8C2HiApJPIrSFZJL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7c1d7d87-618f-46b7-b15e-22c70bc472a0-0', usage_metadata={'input_tokens': 31, 'output_tokens': 18, 'total_tokens': 49, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세션 ID로 히스토리 가져오기\n",
    "get_session_history(\"user1\").messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='기존의 값 3에 숫자 2를 곱하면 3 × 2 = 6입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 61, 'total_tokens': 86, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BmyooQdlCrJtkDctfjAscg6hYs9Sc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--213d0e03-e227-4f7e-ae42-e83eb6ef1e69-0' usage_metadata={'input_tokens': 61, 'output_tokens': 25, 'total_tokens': 86, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 히스토리 이용해서 대화 진행\n",
    "response = chain_with_history.invoke(\n",
    "    {\"subject\": \"수학\", \"question\": \"여기에 숫자 2를 곱하면 얼마인가요?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='1+2는 얼마인가요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='1+2는 3입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 31, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BmynRtwDqtMqjU6mLiIaW9Wpp2Geg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--269f4a6d-6b3e-4ec2-882f-b5d418fcc79b-0', usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='여기에 숫자 2를 곱하면 얼마인가요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='기존의 값 3에 숫자 2를 곱하면 3 × 2 = 6입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 61, 'total_tokens': 86, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BmyooQdlCrJtkDctfjAscg6hYs9Sc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--213d0e03-e227-4f7e-ae42-e83eb6ef1e69-0', usage_metadata={'input_tokens': 61, 'output_tokens': 25, 'total_tokens': 86, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세션 ID로 히스토리 가져오기\n",
    "get_session_history(\"user1\").messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 에이전트 (Agent)\n",
    "- 자율적 의사결정이 가능한 실행 단위\n",
    "- LangChain에서는 Agent 클래스를 통해 에이전트 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 100, 'b': 200}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m300.0\u001b[0m\u001b[32;1m\u001b[1;3m100과 200을 더하면 300입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '100과 200을 더하면 얼마인가요?', 'output': '100과 200을 더하면 300입니다.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# 프롬프트 템플릿 생성 - ReAct 에이전트에 필요한 변수들 포함\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친절한 수학 선생님입니다.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")    # 에이전트가 도구 호출 결과를 기록할 플레이스홀더\n",
    "])\n",
    "\n",
    "# 도구 정의\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"두 숫자를 더하는 도구\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def subtract(a: float, b: float) -> float:\n",
    "    \"\"\"두 숫자를 빼는 도구\"\"\"\n",
    "    return a - b\n",
    "\n",
    "# 도구 목록 생성\n",
    "tools = [\n",
    "    add,\n",
    "    subtract\n",
    "]\n",
    "\n",
    "# 에이전트 생성 (도구 호출)\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=ChatOpenAI(model='gpt-4.1-mini'),\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# 에이전트 실행 도구 정의\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,      # 도구 호출 에이전트\n",
    "    tools=tools,      # 도구 목록\n",
    "    verbose=True,     # 상세 로그 출력\n",
    "    )\n",
    "\n",
    "# 에이전트 실행\n",
    "agent_executor.invoke({\"input\": \"100과 200을 더하면 얼마인가요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## [실습]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 다음 조건을 만족하는 새로운 ChatPromptTemplate을 만드세요.\n",
    "   - 시스템 메시지: \"당신은 친절한 과학 선생님입니다\"\n",
    "   - 대화 기록을 포함\n",
    "   - 사용자 질문을 받을 수 있는 형식\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='당신은 친절한 과학 선생님입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='인공지능에 대해 설명해주세요', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# 여기에 코드를 작성하세요.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 채팅 템플릿 생성\n",
    "# 여기서는 시스템 메시지와 사용자 메시지를 포함하여 정의\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친절한 과학 선생님입니다.\"),\n",
    "    (\"user\", \"{question}에 대해 설명해주세요\")\n",
    "])\n",
    "\n",
    "# 템플릿 사용\n",
    "prompt = template.invoke({\"question\": \"인공지능\"})\n",
    "\n",
    "# 출력\n",
    "prompt\n",
    "\n",
    "print(prompt.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. StrOutputParser를 사용하여 다음을 구현해보세요.\n",
    "   - 앞의 프롬프트 템플릿을 사용하여 체인 구성 및 실행\n",
    "   - \"섭씨온도와 화씨온도 관계\"를 설명해 달라고 요청하는 프롬프트 작성 \n",
    "   - 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네! 섭씨온도(°C)와 화씨온도(°F)는 온도를 나타내는 두 가지 다른 단위입니다. 이 두 온도 단위는 서로 다른 기준을 사용하지만, 온도 변환 공식으로 서로 쉽게 바꿀 수 있습니다.\n",
      "\n",
      "### 섭씨와 화씨의 기본 개념\n",
      "- **섭씨(°C)**: 얼음이 녹는 점을 0도, 물이 끓는 점을 100도로 정한 온도 단위입니다. 주로 전 세계적으로 널리 사용됩니다.\n",
      "- **화씨(°F)**: 얼음이 녹는 점을 32도, 물이 끓는 점을 212도로 정한 온도 단위입니다. 주로 미국에서 많이 사용됩니다.\n",
      "\n",
      "### 온도 변환 공식\n",
      "- 섭씨 온도를 화씨 온도로 바꾸는 공식:\n",
      "  \\[\n",
      "  F = \\frac{9}{5} \\times C + 32\n",
      "  \\]\n",
      "- 화씨 온도를 섭씨 온도로 바꾸는 공식:\n",
      "  \\[\n",
      "  C = \\frac{5}{9} \\times (F - 32)\n",
      "  \\]\n",
      "\n",
      "### 예시\n",
      "- 섭씨 0도는 화씨로:\n",
      "  \\[\n",
      "  F = \\frac{9}{5} \\times 0 + 32 = 32°F\n",
      "  \\]\n",
      "- 화씨 212도는 섭씨로:\n",
      "  \\[\n",
      "  C = \\frac{5}{9} \\times (212 - 32) = \\frac{5}{9} \\times 180 = 100°C\n",
      "  \\]\n",
      "\n",
      "이렇게 두 온도 단위는 서로 변환할 수 있고, 각각의 특징에 따라 사용처가 다릅니다. 궁금한 점 있으면 더 물어보세요!\n"
     ]
    }
   ],
   "source": [
    "# 여기에 코드를 작성하세요.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 채팅 템플릿 생성\n",
    "# 여기서는 시스템 메시지와 사용자 메시지를 포함하여 정의\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친절한 과학 선생님입니다.\"),\n",
    "    (\"user\", \"{question}에 대해 설명해주세요\")\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4.1-mini')\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = template | model | parser\n",
    "\n",
    "result = chain.invoke({\"question\":\"섭씨온도와 화씨온도 관계\"})\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
