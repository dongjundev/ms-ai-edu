{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f191d1cf",
   "metadata": {},
   "source": [
    "#  RAG 체인 구성\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641ec21",
   "metadata": {},
   "source": [
    "# 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be5eb8",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829d8712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5989430",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa02fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69732dd",
   "metadata": {},
   "source": [
    "# 다양한 문서 형식 처리하기\n",
    "\n",
    "- 역할: Document Loader는 다양한 소스에서 문서를 로드\n",
    "- 구현: \n",
    "    - Document Loader는 BaseLoader 인터페이스를 통해서 구현\n",
    "    - `.load()` 또는 `.lazy_load()` 메서드를 통해 동일한 방식으로 호출 \n",
    "    - 대용량 데이터셋의 경우 메모리 효율을 위해 `.lazy_load()`를 사용하는 것을 권장 \n",
    "- 종류:\n",
    "    - PDF 파일 로더\n",
    "    - 웹 페이지 로더 \n",
    "    - CSV 데이터 로더\n",
    "    - 디렉토리 로더\n",
    "    - HTML 데이터 로더\n",
    "    - JSON 데이터 로더\n",
    "    - Markdown 데이터 로더\n",
    "    - Microsoft Office 데이터 로더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ca1af2",
   "metadata": {},
   "source": [
    "### 1. **웹 문서 로더**\n",
    "\n",
    "- uv add bs4 langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e50f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 기본적인 텍스트 추출\n",
    "web_loader = WebBaseLoader(\n",
    "    web_paths=[\n",
    "        \"https://python.langchain.com/\", \n",
    "        \"https://js.langchain.com/\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# 동기 로딩\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "len(web_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f173ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://python.langchain.com/',\n",
       " 'title': 'Introduction | 🦜️🔗 LangChain',\n",
       " 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).',\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13cdeb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Introduction | 🦜️🔗 LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyIntroductionOn this pageIntroduction\n",
      "LangChain is a framework for developing applications powered by large language models (LLMs).\n",
      "LangChain simplifies every stage of the LLM application lifecycle:\n",
      "\n",
      "Development: Build your applications using LangChain's open-source components and third-party integrations.\n",
      "Use LangGraph to build stateful agents with first-class streaming and human-in-the-loop support.\n",
      "Productionization: Use LangSmith to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.\n",
      "Deployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Platform.\n",
      "\n",
      "\n",
      "\n",
      "LangChain implements a standard interface for large language models and related\n",
      "technologies, such as embedding models and vector stores, and integrates with\n",
      "hundreds of providers. See the integrations page for\n",
      "more.\n",
      "\n",
      "Select chat model:Google Gemini▾OpenAIAnthropicAzureGoogle GeminiGoogle VertexAWSGroqCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabricksxAIPerplexitypip install -qU \"langchain[google-genai]\"import getpassimport osif not os.environ.get(\"GOOGLE_API_KEY\"):  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")from langchain.chat_models import init_chat_modelmodel = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
      "model.invoke(\"Hello, world!\")\n",
      "noteThese docs focus on the Python LangChain library. Head here for docs on the JavaScript LangChain library.\n",
      "Architecture​\n",
      "The LangChain framework consists of multiple open-source libraries. Read more in the\n",
      "Architecture page.\n",
      "\n",
      "langchain-core: Base abstractions for chat models and other components.\n",
      "Integration packages (e.g. langchain-openai, langchain-anthropic, etc.): Important integrations have been split into lightweight packages that are co-maintained by the LangChain team and the integration developers.\n",
      "langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture.\n",
      "langchain-community: Third-party integrations that are community maintained.\n",
      "langgraph: Orchestration framework for combining LangChain components into production-ready applications with persistence, streaming, and other key features. See LangGraph documentation.\n",
      "\n",
      "Guides​\n",
      "Tutorials​\n",
      "If you're looking to build something specific or are more of a hands-on learner, check out our tutorials section.\n",
      "This is the best place to get started.\n",
      "These are the best ones to get started with:\n",
      "\n",
      "Build a Simple LLM Application\n",
      "Build a Chatbot\n",
      "Build an Agent\n",
      "Introduction to LangGraph\n",
      "\n",
      "Explore the full list of LangChain tutorials here, and check out other LangGraph tutorials here. To learn more about LangGraph, check out our first LangChain Academy course, Introduction to LangGraph, available here.\n",
      "How-to guides​\n",
      "Here you’ll find short answers to “How do I….?” types of questions.\n",
      "These how-to guides don’t cover topics in depth – you’ll find that material in the Tutorials and the API Reference.\n",
      "However, these guides will help you quickly accomplish common tasks using chat models,\n",
      "vector stores, and other common LangChain components.\n",
      "Check out LangGraph-specific how-tos here.\n",
      "Conceptual guide​\n",
      "Introductions to all the key parts of LangChain you’ll need to know! Here you'll find high level explanations of all LangChain concepts.\n",
      "For a deeper dive into LangGraph concepts, check out this page.\n",
      "Integrations​\n",
      "LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\n",
      "If you're looking to get up and running quickly with chat models, vector stores,\n",
      "or other LangChain components from a specific provider, check out our growing list of integrations.\n",
      "API reference​\n",
      "Head to the reference section for full documentation of all classes and methods in the LangChain Python packages.\n",
      "Ecosystem​\n",
      "🦜🛠️ LangSmith​\n",
      "Trace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\n",
      "🦜🕸️ LangGraph​\n",
      "Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by Linkedin, Uber, Klarna, GitLab, and many more.\n",
      "Additional resources​\n",
      "Versions​\n",
      "See what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\n",
      "Security​\n",
      "Read up on security best practices to make sure you're developing safely with LangChain.\n",
      "Contributing​\n",
      "Check out the developer's guide for guidelines on contributing and help getting your dev environment set up.Edit this pageNextTutorialsArchitectureGuidesTutorialsHow-to guidesConceptual guideIntegrationsAPI referenceEcosystem🦜🛠️ LangSmith🦜🕸️ LangGraphAdditional resourcesVersionsSecurityContributingCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(web_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645da45b",
   "metadata": {},
   "source": [
    "### 2. **CSV 파일 로더**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75179f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 10\n",
      "--------------------------------------------------\n",
      "처음 문서의 메타데이터: \n",
      " {'source': './data/kbo_teams_2023.csv', 'row': 0}\n",
      "--------------------------------------------------\n",
      "처음 문서의 내용: \n",
      " Team: KIA 타이거즈\n",
      "City: 광주\n",
      "Founded: 1982\n",
      "Home Stadium: 광주-기아 챔피언스 필드\n",
      "Championships: 11\n",
      "Introduction: KBO 리그의 전통 강호로, 역대 최다 우승 기록을 보유하고 있다. '타이거즈 스피릿'으로 유명하며, 양현종, 안치홍 등 스타 선수들을 배출했다. 광주를 연고로 하는 유일한 프로야구팀으로 지역 사랑이 강하다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# 기본 파일 로드\n",
    "csv_loader = CSVLoader(\"./data/kbo_teams_2023.csv\", encoding=\"utf-8\")\n",
    "csv_docs = csv_loader.load()\n",
    "\n",
    "print(\"문서의 수:\", len(csv_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 메타데이터: \\n\", csv_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 내용: \\n\", csv_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a5e089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 10\n",
      "--------------------------------------------------\n",
      "처음 문서의 메타데이터: \n",
      " {'source': 'KIA 타이거즈', 'row': 0}\n",
      "--------------------------------------------------\n",
      "처음 문서의 내용: \n",
      " Team: KIA 타이거즈\n",
      "City: 광주\n",
      "Founded: 1982\n",
      "Home Stadium: 광주-기아 챔피언스 필드\n",
      "Championships: 11\n",
      "Introduction: KBO 리그의 전통 강호로, 역대 최다 우승 기록을 보유하고 있다. '타이거즈 스피릿'으로 유명하며, 양현종, 안치홍 등 스타 선수들을 배출했다. 광주를 연고로 하는 유일한 프로야구팀으로 지역 사랑이 강하다.\n"
     ]
    }
   ],
   "source": [
    "## 소스 컬럼 지정\n",
    "\n",
    "csv_loader = CSVLoader(\n",
    "    file_path=\"./data/kbo_teams_2023.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    source_column=\"Team\"  # 이 컬럼의 값이 메타데이터의 source로 사용됨\n",
    ")\n",
    "\n",
    "csv_docs = csv_loader.load()\n",
    "\n",
    "print(\"문서의 수:\", len(csv_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 메타데이터: \\n\", csv_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 내용: \\n\", csv_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d28ef",
   "metadata": {},
   "source": [
    "### 3. **PDF 파일 로더**\n",
    "\n",
    "- uv add langchain_community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90aa754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 문서 개수: 20\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 로더 초기화 (근로기준법 문서)\n",
    "pdf_loader = PyPDFLoader('./data/labor_law.pdf')\n",
    "\n",
    "# 동기 로딩\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb33946",
   "metadata": {},
   "source": [
    "# 텍스트 분할(Text Splitting) \n",
    "\n",
    "- 대규모 텍스트 문서를 처리할 때 매우 중요한 전처리 단계\n",
    "- 고려사항:\n",
    "    1. 문서의 구조와 형식\n",
    "    2. 원하는 청크 크기\n",
    "    3. 문맥 보존의 중요도\n",
    "    4. 처리 속도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a007e618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 문서: page_content='법제처                                                            1                                                       국가법령정보센터\n",
      "근로기준법\n",
      " \n",
      "근로기준법\n",
      "[시행 2021. 11. 19.] [법률 제18176호, 2021. 5. 18., 일부개정]\n",
      "고용노동부 (근로기준정책과 - 해고, 취업규칙, 기타) 044-202-7534\n",
      "고용노동부 (근로기준정책과 - 소년) 044-202-7535\n",
      "고용노동부 (근로기준정책과 - 임금) 044-202-7548\n",
      "고용노동부 (여성고용정책과 - 여성) 044-202-7475\n",
      "고용노동부 (임금근로시간정책과 - 근로시간, 휴게) 044-202-7545\n",
      "고용노동부 (임금근로시간정책과 - 휴일, 연차휴가) 044-202-7973\n",
      "고용노동부 (임금근로시간정책과 - 제63조 적용제외, 특례업종) 044-202-7530\n",
      "고용노동부 (임금근로시간정책과 - 유연근로시간제) 044-202-7549\n",
      "       제1장 총칙\n",
      " \n",
      "제1조(목적) 이 법은 헌법에 따라 근로조건의 기준을 정함으로써 근로자의 기본적 생활을 보장, 향상시키며 균형 있는\n",
      "국민경제의 발전을 꾀하는 것을 목적으로 한다.\n",
      " \n",
      "제2조(정의) ① 이 법에서 사용하는 용어의 뜻은 다음과 같다. <개정 2018. 3. 20., 2019. 1. 15., 2020. 5. 26.>\n",
      "1. “근로자”란 직업의 종류와 관계없이 임금을 목적으로 사업이나 사업장에 근로를 제공하는 사람을 말한다.\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "말한다.\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n",
      "5. “임금”이란 사용자가 근로의 대가로 근로자에게 임금, 봉급, 그 밖에 어떠한 명칭으로든지 지급하는 모든 금품을\n",
      "말한다.\n",
      "6. “평균임금”이란 이를 산정하여야 할 사유가 발생한 날 이전 3개월 동안에 그 근로자에게 지급된 임금의 총액을\n",
      "그 기간의 총일수로 나눈 금액을 말한다. 근로자가 취업한 후 3개월 미만인 경우도 이에 준한다.\n",
      "7. “1주”란 휴일을 포함한 7일을 말한다.\n",
      "8. “소정(所定)근로시간”이란 제50조, 제69조 본문 또는 「산업안전보건법」 제139조제1항에 따른 근로시간의 범위에\n",
      "서 근로자와 사용자 사이에 정한 근로시간을 말한다.\n",
      "9. “단시간근로자”란 1주 동안의 소정근로시간이 그 사업장에서 같은 종류의 업무에 종사하는 통상 근로자의 1주\n",
      "동안의 소정근로시간에 비하여 짧은 근로자를 말한다.\n",
      "② 제1항제6호에 따라 산출된 금액이 그 근로자의 통상임금보다 적으면 그 통상임금액을 평균임금으로 한다.\n",
      " \n",
      "제3조(근로조건의 기준) 이 법에서 정하는 근로조건은 최저기준이므로 근로 관계 당사자는 이 기준을 이유로 근로조건\n",
      "을 낮출 수 없다.\n",
      " \n",
      "제4조(근로조건의 결정) 근로조건은 근로자와 사용자가 동등한 지위에서 자유의사에 따라 결정하여야 한다.\n",
      " \n",
      "제5조(근로조건의 준수) 근로자와 사용자는 각자가 단체협약, 취업규칙과 근로계약을 지키고 성실하게 이행할 의무가\n",
      "있다.\n",
      " \n",
      "제6조(균등한 처우) 사용자는 근로자에 대하여 남녀의 성(性)을 이유로 차별적 대우를 하지 못하고, 국적ㆍ신앙 또는 사\n",
      "회적 신분을 이유로 근로조건에 대한 차별적 처우를 하지 못한다.\n",
      " \n",
      "제7조(강제 근로의 금지) 사용자는 폭행, 협박, 감금, 그 밖에 정신상 또는 신체상의 자유를 부당하게 구속하는 수단으로\n",
      "써 근로자의 자유의사에 어긋나는 근로를 강요하지 못한다.' metadata={'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2024-10-15T14:45:34+09:00', 'moddate': '2024-10-15T14:45:34+09:00', 'source': './data/labor_law.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(f'첫 번째 문서: {pdf_docs[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "742f6597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 문서의 텍스트 길이: 1811\n"
     ]
    }
   ],
   "source": [
    "long_text = pdf_docs[0].page_content\n",
    "print(f'첫 번째 문서의 텍스트 길이: {len(long_text)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a5ec79",
   "metadata": {},
   "source": [
    "### 1. **CharacterTextSplitter**\n",
    "- 가장 기본적인 분할 방식\n",
    "- 문자 수를 기준으로 텍스트를 분할\n",
    "- 단순하지만 문맥을 고려하지 않는다는 단점이 있음\n",
    "\n",
    "- 설치: pip install langchain_text_splitters 또는 uv add langchain_text_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8821e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 텍스트 개수: 1\n",
      "첫 번째 분할된 텍스트: 법제처                                                            1                                                       국가법령정보센터\n",
      "근로기준법\n",
      " \n",
      "근로기준법\n",
      "[시행 2021. 11. 19.] [법률 제18176호, 2021. 5. 18., 일부개정]\n",
      "고용노동부 (근로기준정책과 - 해고, 취업규칙, 기타) 044-202-7534\n",
      "고용노동부 (근로기준정책과 - 소년) 044-202-7535\n",
      "고용노동부 (근로기준정책과 - 임금) 044-202-7548\n",
      "고용노동부 (여성고용정책과 - 여성) 044-202-7475\n",
      "고용노동부 (임금근로시간정책과 - 근로시간, 휴게) 044-202-7545\n",
      "고용노동부 (임금근로시간정책과 - 휴일, 연차휴가) 044-202-7973\n",
      "고용노동부 (임금근로시간정책과 - 제63조 적용제외, 특례업종) 044-202-7530\n",
      "고용노동부 (임금근로시간정책과 - 유연근로시간제) 044-202-7549\n",
      "       제1장 총칙\n",
      " \n",
      "제1조(목적) 이 법은 헌법에 따라 근로조건의 기준을 정함으로써 근로자의 기본적 생활을 보장, 향상시키며 균형 있는\n",
      "국민경제의 발전을 꾀하는 것을 목적으로 한다.\n",
      " \n",
      "제2조(정의) ① 이 법에서 사용하는 용어의 뜻은 다음과 같다. <개정 2018. 3. 20., 2019. 1. 15., 2020. 5. 26.>\n",
      "1. “근로자”란 직업의 종류와 관계없이 임금을 목적으로 사업이나 사업장에 근로를 제공하는 사람을 말한다.\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "말한다.\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n",
      "5. “임금”이란 사용자가 근로의 대가로 근로자에게 임금, 봉급, 그 밖에 어떠한 명칭으로든지 지급하는 모든 금품을\n",
      "말한다.\n",
      "6. “평균임금”이란 이를 산정하여야 할 사유가 발생한 날 이전 3개월 동안에 그 근로자에게 지급된 임금의 총액을\n",
      "그 기간의 총일수로 나눈 금액을 말한다. 근로자가 취업한 후 3개월 미만인 경우도 이에 준한다.\n",
      "7. “1주”란 휴일을 포함한 7일을 말한다.\n",
      "8. “소정(所定)근로시간”이란 제50조, 제69조 본문 또는 「산업안전보건법」 제139조제1항에 따른 근로시간의 범위에\n",
      "서 근로자와 사용자 사이에 정한 근로시간을 말한다.\n",
      "9. “단시간근로자”란 1주 동안의 소정근로시간이 그 사업장에서 같은 종류의 업무에 종사하는 통상 근로자의 1주\n",
      "동안의 소정근로시간에 비하여 짧은 근로자를 말한다.\n",
      "② 제1항제6호에 따라 산출된 금액이 그 근로자의 통상임금보다 적으면 그 통상임금액을 평균임금으로 한다.\n",
      " \n",
      "제3조(근로조건의 기준) 이 법에서 정하는 근로조건은 최저기준이므로 근로 관계 당사자는 이 기준을 이유로 근로조건\n",
      "을 낮출 수 없다.\n",
      " \n",
      "제4조(근로조건의 결정) 근로조건은 근로자와 사용자가 동등한 지위에서 자유의사에 따라 결정하여야 한다.\n",
      " \n",
      "제5조(근로조건의 준수) 근로자와 사용자는 각자가 단체협약, 취업규칙과 근로계약을 지키고 성실하게 이행할 의무가\n",
      "있다.\n",
      " \n",
      "제6조(균등한 처우) 사용자는 근로자에 대하여 남녀의 성(性)을 이유로 차별적 대우를 하지 못하고, 국적ㆍ신앙 또는 사\n",
      "회적 신분을 이유로 근로조건에 대한 차별적 처우를 하지 못한다.\n",
      " \n",
      "제7조(강제 근로의 금지) 사용자는 폭행, 협박, 감금, 그 밖에 정신상 또는 신체상의 자유를 부당하게 구속하는 수단으로\n",
      "써 근로자의 자유의사에 어긋나는 근로를 강요하지 못한다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter \n",
    "\n",
    "# 텍스트 분할기 초기화 (기본 설정값 적용 )\n",
    "text_splitter = CharacterTextSplitter(\n",
    "\n",
    "    # CharacterTextSplitter의 기본 설정값\n",
    "    separator = \"\\n\\n\",         # 청크 구분자: 두 개의 개행문자\n",
    "    is_separator_regex = False,  # 구분자가 정규식인지 여부\n",
    "\n",
    "    # TextSplitter의 기본 설정값\n",
    "    chunk_size = 1000,          # 청크 길이\n",
    "    chunk_overlap = 200,        # 청크 중첩\n",
    "    length_function = len,      # 길이 함수 (문자열 길이)\n",
    "    keep_separator = False,     # 구분자 유지 여부\n",
    "    add_start_index = False,   # 시작 인덱스 추가 여부\n",
    "    strip_whitespace = True,   # 공백 제거 여부\n",
    ")\n",
    "\n",
    "# 텍스트 분할 - split_text() 메서드 사용\n",
    "texts = text_splitter.split_text(long_text)\n",
    "\n",
    "# 분할된 텍스트 개수 출력\n",
    "print(f'분할된 텍스트 개수: {len(texts)}')\n",
    "\n",
    "# 첫 번째 분할된 텍스트 출력\n",
    "print(f'첫 번째 분할된 텍스트: {texts[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5febd9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 텍스트 개수: 3\n",
      "청크 1의 텍스트 길이: 936\n",
      "청크 2의 텍스트 길이: 944\n",
      "청크 3의 텍스트 길이: 273\n",
      "첫 번째 청크의 텍스트: 법제처                                                            1                                                       국가법령정보센터\n",
      "근로기준법\n",
      " \n",
      "근로기준법\n",
      "[시행 2021. 11. 19.] [법률 제18176호, 2021. 5. 18., 일부개정]\n",
      "고용노동부 (근로기준정책과 - 해고, 취업규칙, 기타) 044-202-7534\n",
      "고용노동부 (근로기준정책과 - 소년) 044-202-7535\n",
      "고용노동부 (근로기준정책과 - 임금) 044-202-7548\n",
      "고용노동부 (여성고용정책과 - 여성) 044-202-7475\n",
      "고용노동부 (임금근로시간정책과 - 근로시간, 휴게) 044-202-7545\n",
      "고용노동부 (임금근로시간정책과 - 휴일, 연차휴가) 044-202-7973\n",
      "고용노동부 (임금근로시간정책과 - 제63조 적용제외, 특례업종) 044-202-7530\n",
      "고용노동부 (임금근로시간정책과 - 유연근로시간제) 044-202-7549\n",
      "       제1장 총칙\n",
      " \n",
      "제1조(목적) 이 법은 헌법에 따라 근로조건의 기준을 정함으로써 근로자의 기본적 생활을 보장, 향상시키며 균형 있는\n",
      "국민경제의 발전을 꾀하는 것을 목적으로 한다.\n",
      " \n",
      "제2조(정의) ① 이 법에서 사용하는 용어의 뜻은 다음과 같다. <개정 2018. 3. 20., 2019. 1. 15., 2020. 5. 26.>\n",
      "1. “근로자”란 직업의 종류와 관계없이 임금을 목적으로 사업이나 사업장에 근로를 제공하는 사람을 말한다.\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "말한다.\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 문장 구분자를 개행문자로 설정\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",        # 청크 구분자: 개행문자\n",
    "    chunk_size = 1000,       # 청크 길이\n",
    "    chunk_overlap = 200      # 청크 중첩\n",
    ")\n",
    "\n",
    "# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할\n",
    "chunks = text_splitter.split_documents([pdf_docs[0]])   # 첫 번째 문서만 분할\n",
    "\n",
    "# 분할된 텍스트 개수 출력\n",
    "print(f'분할된 텍스트 개수: {len(chunks)}')\n",
    "\n",
    "# 각 청크의 텍스트 길이 출력\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f'청크 {i+1}의 텍스트 길이: {len(chunk.page_content)}')\n",
    "\n",
    "# 첫 번째 청크의 텍스트 출력\n",
    "print(f'첫 번째 청크의 텍스트: {chunks[0].page_content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7466eb",
   "metadata": {},
   "source": [
    "### 2. **RecursiveCharacterTextSplitter**\n",
    "\n",
    "- 재귀적으로 텍스트를 분할\n",
    "- 구분자를 순차적으로 적용하여 큰 청크에서 시작하여 점진적으로 더 작은 단위로 분할\n",
    "- 문맥을 더 잘 보존할 수 있음  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f67f7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 텍스트 청크 수: 56\n",
      "각 청크의 길이: [936, 944, 273, 941, 942, 941, 963, 637, 971, 991, 420, 946, 985, 563, 953, 980, 341, 961, 997, 661, 996, 957, 336, 951, 987, 367, 966, 959, 697, 981, 967, 950, 959, 842, 990, 975, 440, 966, 970, 448, 947, 967, 413, 939, 997, 393, 952, 958, 255, 987, 687, 997, 975, 377, 978, 888]\n",
      "\n",
      "법제처                                                            1                                                       국가법령정보센터\n",
      "근로기준법\n",
      " \n",
      "근로기준법\n",
      "[시행 2021. 11. 19.] [법률 제18176호, 2021. 5. 18., 일부개정]\n",
      "고용노동부 \n",
      "----------------------------------------------------------------------------------------------------\n",
      " 사업이나 사업장에 근로를 제공하는 사람을 말한다.\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "말한다.\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n",
      "====================================================================================================\n",
      "\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "말한다.\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n",
      "5. “임금”이란 사용자가 근로의 대가로 근로자에게\n",
      "----------------------------------------------------------------------------------------------------\n",
      "등한 지위에서 자유의사에 따라 결정하여야 한다.\n",
      " \n",
      "제5조(근로조건의 준수) 근로자와 사용자는 각자가 단체협약, 취업규칙과 근로계약을 지키고 성실하게 이행할 의무가\n",
      "있다.\n",
      " \n",
      "제6조(균등한 처우) 사용자는 근로자에 대하여 남녀의 성(性)을 이유로 차별적 대우를 하지 못하고, 국적ㆍ신앙 또는 사\n",
      "회적 신분을 이유로 근로조건에 대한 차별적 처우를 하지 못한다.\n",
      "====================================================================================================\n",
      "\n",
      "제5조(근로조건의 준수) 근로자와 사용자는 각자가 단체협약, 취업규칙과 근로계약을 지키고 성실하게 이행할 의무가\n",
      "있다.\n",
      " \n",
      "제6조(균등한 처우) 사용자는 근로자에 대하여 남녀의 성(性)을 이유로 차별적 대우를 하지 못하고, 국적ㆍ신앙 또는 사\n",
      "회적 신분을 이유로 근로조건에 대한 차별적 처우를 하지 못한다.\n",
      " \n",
      "제7조(강제 근로의 금지) 사용자는 폭행, 협박\n",
      "----------------------------------------------------------------------------------------------------\n",
      "균등한 처우) 사용자는 근로자에 대하여 남녀의 성(性)을 이유로 차별적 대우를 하지 못하고, 국적ㆍ신앙 또는 사\n",
      "회적 신분을 이유로 근로조건에 대한 차별적 처우를 하지 못한다.\n",
      " \n",
      "제7조(강제 근로의 금지) 사용자는 폭행, 협박, 감금, 그 밖에 정신상 또는 신체상의 자유를 부당하게 구속하는 수단으로\n",
      "써 근로자의 자유의사에 어긋나는 근로를 강요하지 못한다.\n",
      "====================================================================================================\n",
      "\n",
      "법제처                                                            2                                                       국가법령정보센터\n",
      "근로기준법\n",
      "제8조(폭행의 금지) 사용자는 사고의 발생이나 그 밖의 어떠한 이유로도 근로자에게 폭행을 하지 못한다.\n",
      " \n",
      "제9조(중간\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ㆍ도, 시ㆍ군ㆍ구, 읍ㆍ면ㆍ동, 그 밖에 이에\n",
      "준하는 것에 대하여도 적용된다.\n",
      " \n",
      "제13조(보고, 출석의 의무) 사용자 또는 근로자는 이 법의 시행에 관하여 고용노동부장관ㆍ「노동위원회법」에 따른 노\n",
      "동위원회(이하 “노동위원회”라 한다) 또는 근로감독관의 요구가 있으면 지체 없이 필요한 사항에 대하여 보고하거나\n",
      "출석하여야 한다. <개정 2010. 6. 4.>\n",
      "====================================================================================================\n",
      "\n",
      "준하는 것에 대하여도 적용된다.\n",
      " \n",
      "제13조(보고, 출석의 의무) 사용자 또는 근로자는 이 법의 시행에 관하여 고용노동부장관ㆍ「노동위원회법」에 따른 노\n",
      "동위원회(이하 “노동위원회”라 한다) 또는 근로감독관의 요구가 있으면 지체 없이 필요한 사항에 대하여 보고하거나\n",
      "출석하여야 한다. <개정 2010. 6. 4.>\n",
      " \n",
      "제14조(법령 주요 내용 등의 게시) ① \n",
      "----------------------------------------------------------------------------------------------------\n",
      "함]\n",
      " \n",
      "제17조(근로조건의 명시) ① 사용자는 근로계약을 체결할 때에 근로자에게 다음 각 호의 사항을 명시하여야 한다. 근로\n",
      "계약 체결 후 다음 각 호의 사항을 변경하는 경우에도 또한 같다. <개정 2010. 5. 25.>\n",
      "1. 임금\n",
      "2. 소정근로시간\n",
      "3. 제55조에 따른 휴일\n",
      "4. 제60조에 따른 연차 유급휴가\n",
      "5. 그 밖에 대통령령으로 정하는 근로조건\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 재귀적 텍스트 분할기 초기화\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,             # 청크 크기  \n",
    "    chunk_overlap=200,           # 청크 중 중복되는 부분 크기\n",
    "    length_function=len,         # 글자 수를 기준으로 분할\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # 구분자 - 재귀적으로 순차적으로 적용 \n",
    ")\n",
    "\n",
    "# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할\n",
    "chunks = text_splitter.split_documents(pdf_docs)\n",
    "print(f\"생성된 텍스트 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "# 각 청크의 시작 부분과 끝 부분 확인 - 5개 청크만 출력\n",
    "for chunk in chunks[:5]:\n",
    "    print(chunk.page_content[:200])\n",
    "    print(\"-\" * 100)\n",
    "    print(chunk.page_content[-200:])\n",
    "    print(\"=\" * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0ecd1d",
   "metadata": {},
   "source": [
    "### 3. **정규표현식 사용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9134516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 텍스트 청크 수: 55\n",
      "각 청크의 길이: [939, 944, 273, 937, 922, 941, 986, 561, 971, 973, 387, 946, 751, 764, 935, 957, 401, 826, 890, 830, 996, 998, 951, 985, 274, 961, 889, 776, 947, 926, 999, 996, 479, 929, 890, 594, 961, 963, 409, 947, 998, 329, 866, 954, 464, 955, 989, 255, 999, 670, 923, 912, 291, 981, 880]\n",
      "\n",
      "법제처                                                            1                                                       국가법령정보센터\n",
      "근로기준법\n",
      " \n",
      "근로기준법\n",
      "[시행 2021. 11. 19.] [법률 제18176호, 2021. 5. 18., 일부개정]\n",
      "고용노동부 \n",
      "...\n",
      "이나 사업장에 근로를 제공하는 사람을 말한다.\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "말한다.\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n",
      "5.\n",
      "====================================================================================================\n",
      "\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "말한다.\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n",
      "5. “임금”이란 사용자가 근로의 대가로 근로자에게\n",
      "...\n",
      "등한 지위에서 자유의사에 따라 결정하여야 한다.\n",
      " \n",
      "제5조(근로조건의 준수) 근로자와 사용자는 각자가 단체협약, 취업규칙과 근로계약을 지키고 성실하게 이행할 의무가\n",
      "있다.\n",
      " \n",
      "제6조(균등한 처우) 사용자는 근로자에 대하여 남녀의 성(性)을 이유로 차별적 대우를 하지 못하고, 국적ㆍ신앙 또는 사\n",
      "회적 신분을 이유로 근로조건에 대한 차별적 처우를 하지 못한다.\n",
      "====================================================================================================\n",
      "\n",
      "제5조(근로조건의 준수) 근로자와 사용자는 각자가 단체협약, 취업규칙과 근로계약을 지키고 성실하게 이행할 의무가\n",
      "있다.\n",
      " \n",
      "제6조(균등한 처우) 사용자는 근로자에 대하여 남녀의 성(性)을 이유로 차별적 대우를 하지 못하고, 국적ㆍ신앙 또는 사\n",
      "회적 신분을 이유로 근로조건에 대한 차별적 처우를 하지 못한다.\n",
      " \n",
      "제7조(강제 근로의 금지) 사용자는 폭행, 협박\n",
      "...\n",
      "균등한 처우) 사용자는 근로자에 대하여 남녀의 성(性)을 이유로 차별적 대우를 하지 못하고, 국적ㆍ신앙 또는 사\n",
      "회적 신분을 이유로 근로조건에 대한 차별적 처우를 하지 못한다.\n",
      " \n",
      "제7조(강제 근로의 금지) 사용자는 폭행, 협박, 감금, 그 밖에 정신상 또는 신체상의 자유를 부당하게 구속하는 수단으로\n",
      "써 근로자의 자유의사에 어긋나는 근로를 강요하지 못한다.\n",
      "====================================================================================================\n",
      "\n",
      "법제처                                                            2                                                       국가법령정보센터\n",
      "근로기준법\n",
      "제8조(폭행의 금지) 사용자는 사고의 발생이나 그 밖의 어떠한 이유로도 근로자에게 폭행을 하지 못한다.\n",
      " \n",
      "제9조(중간\n",
      "...\n",
      "ㆍ광역시ㆍ도, 시ㆍ군ㆍ구, 읍ㆍ면ㆍ동, 그 밖에 이에\n",
      "준하는 것에 대하여도 적용된다.\n",
      " \n",
      "제13조(보고, 출석의 의무) 사용자 또는 근로자는 이 법의 시행에 관하여 고용노동부장관ㆍ「노동위원회법」에 따른 노\n",
      "동위원회(이하 “노동위원회”라 한다) 또는 근로감독관의 요구가 있으면 지체 없이 필요한 사항에 대하여 보고하거나\n",
      "출석하여야 한다. <개정 2010. 6.\n",
      "====================================================================================================\n",
      "\n",
      "제13조(보고, 출석의 의무) 사용자 또는 근로자는 이 법의 시행에 관하여 고용노동부장관ㆍ「노동위원회법」에 따른 노\n",
      "동위원회(이하 “노동위원회”라 한다) 또는 근로감독관의 요구가 있으면 지체 없이 필요한 사항에 대하여 보고하거나\n",
      "출석하여야 한다. <개정 2010. 6. 4.>\n",
      " \n",
      "제14조(법령 주요 내용 등의 게시) ① 사용자는 이 법과 이 법에 따른 대통\n",
      "...\n",
      "함]\n",
      " \n",
      "제17조(근로조건의 명시) ① 사용자는 근로계약을 체결할 때에 근로자에게 다음 각 호의 사항을 명시하여야 한다. 근로\n",
      "계약 체결 후 다음 각 호의 사항을 변경하는 경우에도 또한 같다. <개정 2010. 5. 25.>\n",
      "1. 임금\n",
      "2. 소정근로시간\n",
      "3. 제55조에 따른 휴일\n",
      "4. 제60조에 따른 연차 유급휴가\n",
      "5. 그 밖에 대통령령으로 정하는 근로조건\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 문장을 구분하여 분할 - 정규표현식 사용 (문장 구분자: 마침표, 느낌표, 물음표 다음에 공백이 오는 경우)\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=r'(?<=[.!?])\\s+',  # 각 Document 객체의 page_content 속성을 문장으로 분할\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    is_separator_regex=True,      # 구분자가 정규식인지 여부: True\n",
    "    keep_separator=True,          # 구분자 유지 여부: True\n",
    ")\n",
    "\n",
    "# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할\n",
    "chunks = text_splitter.split_documents(pdf_docs)  # 모든 문서를 분할\n",
    "print(f\"생성된 텍스트 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "# 각 청크의 시작 부분과 끝 부분 확인 - 5개 청크만 출력\n",
    "for chunk in chunks[:5]:\n",
    "    print(chunk.page_content[:200])\n",
    "    print(\"...\")\n",
    "    print(chunk.page_content[-200:])\n",
    "    print(\"=\" * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac17b61",
   "metadata": {},
   "source": [
    "`(4) 유사도 기반 검색`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4764ba",
   "metadata": {},
   "source": [
    "### 4. **토큰 수를 기반으로 분할**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2721f",
   "metadata": {},
   "source": [
    "`(1) tiktoken`  \n",
    "- OpenAI에서 만든 BPE Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df3a3f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1811"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 문서 객체의 텍스트 길이\n",
    "len(pdf_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58081f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 수: 6\n",
      "각 청크의 길이: [423, 280, 301, 240, 287, 273]\n",
      "법제처                                               \n",
      "--------------------------------------------------\n",
      "202-7545\n",
      "고용노동부 (임금근로시간정책과 - 휴일, 연차휴가) 044-202-7973\n",
      "==================================================\n",
      "\n",
      "고용노동부 (임금근로시간정책과 - 제63조 적용제외, 특례업종) 044-202-7530\n",
      "고\n",
      "--------------------------------------------------\n",
      " 같다. <개정 2018. 3. 20., 2019. 1. 15., 2020. 5. 26.>\n",
      "==================================================\n",
      "\n",
      "1. “근로자”란 직업의 종류와 관계없이 임금을 목적으로 사업이나 사업장에 근로를 제공하는\n",
      "--------------------------------------------------\n",
      "대가로 근로자에게 임금, 봉급, 그 밖에 어떠한 명칭으로든지 지급하는 모든 금품을\n",
      "말한다.\n",
      "==================================================\n",
      "\n",
      "6. “평균임금”이란 이를 산정하여야 할 사유가 발생한 날 이전 3개월 동안에 그 근로자에\n",
      "--------------------------------------------------\n",
      "139조제1항에 따른 근로시간의 범위에\n",
      "서 근로자와 사용자 사이에 정한 근로시간을 말한다.\n",
      "==================================================\n",
      "\n",
      "9. “단시간근로자”란 1주 동안의 소정근로시간이 그 사업장에서 같은 종류의 업무에 종사하\n",
      "--------------------------------------------------\n",
      "건의 결정) 근로조건은 근로자와 사용자가 동등한 지위에서 자유의사에 따라 결정하여야 한다.\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# TikToken 인코더를 사용하여 재귀적 텍스트 분할기 초기화\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", \n",
    "    # model_name=\"gpt-4.1-mini\",\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할\n",
    "chunks = text_splitter.split_documents([pdf_docs[0]])  # 첫 번째 문서만 분할\n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "\n",
    "# 각 청크의 시작 부분과 끝 부분 확인\n",
    "for chunk in chunks[:5]:\n",
    "    print(chunk.page_content[:50])\n",
    "    print(\"-\" * 50)\n",
    "    print(chunk.page_content[-50:])\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd7bff50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297\n",
      "[28617, 243, 38187, 36155, 246, 12216, 220, 16, 26857, 8790]\n",
      "['�', '�', '제', '�', '�', '                                                           ', ' ', '1', '                                                      ', ' �']\n",
      "==================================================\n",
      "\n",
      "259\n",
      "[35495, 27797, 75265, 116, 58189, 64189, 320, 94801, 18202, 230]\n",
      "['고', '용', '�', '�', '동', '부', ' (', '임', '�', '�']\n",
      "==================================================\n",
      "\n",
      "290\n",
      "[16, 13, 1054, 90161, 120, 17835, 26799, 863, 39519, 222]\n",
      "['1', '.', ' “', '�', '�', '로', '자', '”', '�', '�']\n",
      "==================================================\n",
      "\n",
      "239\n",
      "[21, 13, 1054, 169, 237, 231, 90161, 254, 94801, 18202]\n",
      "['6', '.', ' “', '�', '�', '�', '�', '�', '임', '�']\n",
      "==================================================\n",
      "\n",
      "286\n",
      "[24, 13, 1054, 9019, 101, 30426, 63375, 90161, 120, 17835]\n",
      "['9', '.', ' “', '�', '�', '시', '간', '�', '�', '로']\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "# tokenizer = tiktoken.encoding_for_model(\"gpt-4.1-mini\")\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "\n",
    "    # 각 청크를 토큰화\n",
    "    tokens = tokenizer.encode(chunk.page_content)\n",
    "    # 각 청크의 단어 수 확인\n",
    "    print(len(tokens))\n",
    "    # 각 청크의 토큰화 결과 확인 (첫 10개 토큰만 출력)\n",
    "    print(tokens[:10])\n",
    "    # 토큰 ID를 실제 토큰(문자열)로 변환해서 출력\n",
    "    token_strings = [tokenizer.decode([token]) for token in tokens[:10]]\n",
    "    print(token_strings)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5956daaa",
   "metadata": {},
   "source": [
    "`(2) Hugging Face 토크나이저`  \n",
    "- Hugging Face tokenizer 모델의 토큰 수를 기준으로 분할\n",
    "- uv add langchain_huggingface sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d51cdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongjun/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaTokenizerFast(name_or_path='BAAI/bge-m3', vocab_size=250002, model_max_length=8192, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t250001: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5abee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 107687, 5, 20451, 54272, 16367, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 인코딩 - 문장을 토큰(ID)으로 변환\n",
    "tokens = tokenizer.encode(\"안녕하세요. 반갑습니다.\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6a76e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '▁안녕하세요', '.', '▁반', '갑', '습니다', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# 토큰을 출력 (토큰 ID를 실제 토큰(문자열)로 변환)\n",
    "print(tokenizer.convert_ids_to_tokens(tokens)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cfbaec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요. 반갑습니다.\n"
     ]
    }
   ],
   "source": [
    "# 디코딩 - 토큰을 문자열로 변환\n",
    "print(tokenizer.decode(tokens, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c468edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 수: 4\n",
      "각 청크의 길이: [620, 527, 453, 204]\n",
      "\n",
      "284\n",
      "[0, 37668, 4654, 24247, 106, 40343, 10629, 25547, 26444, 24740]\n",
      "['<s>', '▁법', '제', '처', '▁1', '▁국가', '법', '령', '정보', '센터']\n",
      "==================================================\n",
      "\n",
      "264\n",
      "[0, 6600, 304, 6740, 132, 2905, 367, 16, 106, 1504]\n",
      "['<s>', '▁제', '2', '조', '(', '정', '의', ')', '▁1', '▁이']\n",
      "==================================================\n",
      "\n",
      "267\n",
      "[0, 3217, 52, 3999, 2905, 132, 1493, 3779, 16, 23147]\n",
      "['<s>', '▁8.', '▁“', '소', '정', '(', '所', '定', ')', '근']\n",
      "==================================================\n",
      "\n",
      "124\n",
      "[0, 6600, 910, 6740, 132, 83654, 19123, 993, 101840, 6775]\n",
      "['<s>', '▁제', '6', '조', '(', '균', '등', '한', '▁처', '우']\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Huggingface 토크나이저를 사용하여 재귀적 텍스트 분할기 초기화\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할\n",
    "chunks = text_splitter.split_documents([pdf_docs[0]]) # 첫 번째 문서만 분할\n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "\n",
    "    # 각 청크를 토큰화\n",
    "    tokens = tokenizer.encode(chunk.page_content)\n",
    "    # 각 청크의 단어 수 확인\n",
    "    print(len(tokens))\n",
    "    # 각 청크의 토큰화 결과 확인 (첫 10개 토큰만 출력)\n",
    "    print(tokens[:10])\n",
    "    # 토큰 ID를 실제 토큰(문자열)로 변환해서 출력\n",
    "    token_strings = tokenizer.convert_ids_to_tokens(tokens[:10]) \n",
    "    print(token_strings)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0bbc2e",
   "metadata": {},
   "source": [
    "### 5. **Semantic Chunking**\n",
    "\n",
    "- **SemanticChunker**는 텍스트를 의미 단위로 **분할**하는 특수한 텍스트 분할도구 \n",
    "\n",
    "- 단순 길이 기반이 아닌 **의미 기반**으로 텍스트를 청크화하는데 효과적\n",
    "\n",
    "- **breakpoint_threshold_type**: Text Splitting의 다양한 임계값(Threshold) 설정 방식 (통계적 기법) \n",
    "\n",
    "    - **Gradient** 방식: 임베딩 벡터 간의 **기울기 변화**를 기준으로 텍스트를 분할\n",
    "    - **Percentile** 방식: 임베딩 거리의 **백분위수**를 기준으로 분할 지점을 결정\n",
    "    - **Standard Deviation** 방식: 임베딩 거리의 **표준편차**를 활용하여 유의미한 변화점을 찾아서 분할\n",
    "    - **Interquartile** 방식: 임베딩 거리의 **사분위수 범위**를 기준으로 이상치를 감지하여 분할\n",
    "\n",
    "- 설치: pip install langchain_experimental 또는 uv add langchain_experimental\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b01cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker \n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 임베딩 모델을 사용하여 SemanticChunker를 초기화 \n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"),         # OpenAI 임베딩 사용\n",
    "    breakpoint_threshold_type=\"gradient\",  # 임계값 타입 설정 (gradient, percentile, standard_deviation, interquartile)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "956587ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 수: 3\n",
      "각 청크의 길이: [151, 542, 1104]\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tiktoken' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m각 청크의 길이: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mlen\u001b[39m(chunk.page_content)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mchunk\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mchunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m tokenizer = \u001b[43mtiktoken\u001b[49m.get_encoding(\u001b[33m\"\u001b[39m\u001b[33mcl100k_base\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks[:\u001b[32m5\u001b[39m]:\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# 각 청크를 토큰화\u001b[39;00m\n\u001b[32m     12\u001b[39m     tokens = tokenizer.encode(chunk.page_content)\n",
      "\u001b[31mNameError\u001b[39m: name 'tiktoken' is not defined"
     ]
    }
   ],
   "source": [
    "chunks = text_splitter.split_documents([pdf_docs[0]])\n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "\n",
    "    # 각 청크를 토큰화\n",
    "    tokens = tokenizer.encode(chunk.page_content)\n",
    "    # 각 청크의 단어 수 확인\n",
    "    print(len(tokens))\n",
    "    # 각 청크의 내용을 확인\n",
    "    print(chunk.page_content[:100])\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943d4bb",
   "metadata": {},
   "source": [
    "# 문서 임베딩(Document Embedding)\n",
    "\n",
    "- 개념: \n",
    "    - 텍스트를 벡터(숫자 배열)로 변환하는 과정\n",
    "    - 문서의 의미적 특성을 수치화하여 컴퓨터가 이해하고 처리할 수 있는 형태로 변환 \n",
    "\n",
    "- 목적:\n",
    "    - 텍스트 간 유사도 계산 가능\n",
    "    - 벡터 데이터베이스 저장 및 검색\n",
    "    - 의미 기반 문서 검색 구현\n",
    "\n",
    "- LangChain의 임베딩 모델 종류:\n",
    "    - OpenAI 임베딩\n",
    "    - HuggingFace 임베딩 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1028fb3c",
   "metadata": {},
   "source": [
    "### 1. **OpenAI**\n",
    "\n",
    "- LangChain에서 가장 널리 사용되는 임베딩 모델 중 하나\n",
    "\n",
    "- 주요 특징:\n",
    "    1. 고품질의 임베딩 생성\n",
    "    2. 다양한 언어 지원 (다국어 지원)\n",
    "    3. 일관된 성능\n",
    "    4. 손쉬운 통합\n",
    "\n",
    "- 사용시 주의사항:\n",
    "    1. API 키 설정이 필요 (환경 변수 OPENAI_API_KEY)\n",
    "    2. API 사용량에 따른 비용 발생\n",
    "    3. 긴 텍스트는 자동으로 분할되지 않으므로 필요시 TextSplitter를 사용\n",
    "\n",
    "\n",
    "- 모델별 특징\n",
    "    ```\n",
    "    모델                    페이지/달러    MTEB 성능     최대입력\n",
    "    text-embedding-3-small  62,500       62.3%       8191\n",
    "    text-embedding-3-large   9,615       64.6%       8191\n",
    "    text-embedding-ada-002  12,500       61.0%       8191\n",
    "    ```\n",
    "\n",
    "- 임베딩 벡터 특성\n",
    "    1. small: 1536 차원\n",
    "    1. large: 3072 차원\n",
    "    1. dimensions 파라미터로 차원 축소 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d24267",
   "metadata": {},
   "source": [
    "`(1) embedding 모델`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e021e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x1315bdfd0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x1315be900>, model='text-embedding-3-large', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAIEmbeddings 모델 생성\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",  # 사용할 모델 이름\n",
    "    dimensions=None, # 원하는 임베딩 차원 수를 지정 가능 (기본값: None)\n",
    "    )\n",
    "\n",
    "# 임베딩 객체 출력\n",
    "embeddings_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1296c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8191"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임베딩 모델의 컨텍스트 길이 확인\n",
    "embeddings_model.embedding_ctx_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e3cf77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAIEmbeddings 모델 생성할 때 임베딩 차원을 지정하는 예시\n",
    "embeddings_openai = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",  # 사용할 모델 이름\n",
    "    dimensions=1024, # 원하는 임베딩 차원 수를 지정 가능 (기본값: None)\n",
    "    )\n",
    "\n",
    "# 임베딩 모델의 임베딩 차원 확인 \n",
    "embeddings_openai.dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed077e",
   "metadata": {},
   "source": [
    "`(2) embed_documents 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "979cefee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터의 개수: 5\n",
      "임베딩 벡터의 차원: 1024\n",
      "[-0.0026579881086945534, 0.013920078054070473, -0.0028032048139721155, 0.01730155758559704, 0.021222414448857307, -0.05252702906727791, -0.0035889321006834507, 0.05402068793773651, -0.020983843132853508, -0.03667763993144035, 0.007878017611801624, 0.008012861013412476, -0.021388376131653786, -0.03122163563966751, 0.005627155303955078, -0.01792391575872898, -0.047797106206417084, 0.011565489694476128, 0.05933148041367531, -0.052775971591472626, -0.016845161095261574, -0.03192697465419769, -0.0215750839561224, -0.02611829712986946, 0.0050203558057546616, -0.045805562287569046, 0.057879310101270676, 0.02038222923874855, 0.000326413894072175, -0.026844382286071777, 0.056344158947467804, -0.01757124625146389, -0.0344371534883976, -0.07086584717035294, 0.023525139316916466, 0.040702223777770996, 0.0029743534978479147, -0.007831340655684471, -0.005902030039578676, 0.028504004701972008, 0.008702641353011131, 0.031678032130002975, -0.002951015019789338, 0.029893936589360237, -0.02070378139615059, 0.006431034300476313, -0.02972797490656376, 0.004149054642766714, 0.008645592257380486, 0.06518164277076721, -0.02877369336783886, 0.03462385758757591, 0.009174596518278122, -0.04003837704658508, -0.0023390294518321753, 0.10978397727012634, 0.015880506485700607, 0.03369032219052315, 0.004327982198446989, 0.03483131155371666, 0.017446773126721382, 0.017363792285323143, 0.004216476809233427, 0.024085260927677155, -0.059663403779268265, -0.028047608211636543, 0.04186395928263664, 0.03012213483452797, -0.02288203500211239, -0.03360734134912491, 0.010320773348212242, -0.02259160205721855, -0.051863182336091995, 0.02441718615591526, -0.0008038792875595391, -0.014252002350986004, -0.07468298077583313, 0.02929232455790043, 0.014677280560135841, 0.028047608211636543, -0.004893291275948286, 0.0006129579851403832, 0.055223915725946426, -0.06895728409290314, -0.010631952434778214, -0.026263514533638954, -0.0012823170982301235, -0.06634338200092316, -0.061281535774469376, -0.0053730253130197525, -0.03508025407791138, 0.05638565123081207, 0.005048880819231272, 0.00479993736371398, -0.06103258952498436, 0.03721701726317406, 0.07024349272251129, -0.05999532714486122, 0.004369473084807396, 0.03207219019532204, -0.05945594981312752, -0.006591810379177332, 0.03669838607311249, 0.06298264861106873, 0.002160101430490613, -0.024873580783605576, -0.008277364075183868, 0.022819800302386284, -0.024956563487648964, 0.009387236088514328, -0.011689960956573486, -0.005679018329828978, -0.08704715967178345, 0.046718351542949677, -0.06667530536651611, -0.022487875074148178, 0.03279827535152435, -0.026802891865372658, -0.02690661884844303, -0.008458884432911873, -0.02703109011054039, 0.03408448398113251, 0.03966496139764786, -0.005124082323163748, -0.020714154466986656, -0.028545495122671127, 0.017197830602526665, -0.03761117905378342, -0.0288566742092371, -0.0050125764682888985, -0.005596037022769451, -0.030620021745562553, -0.013961568474769592, 0.032196663320064545, 0.04800456017255783, -0.019013041630387306, 0.0060316878370940685, 0.028981145471334457, -0.001542929676361382, -0.061281535774469376, 0.02215595170855522, -0.022467130795121193, 0.020475583150982857, 0.014708397909998894, -0.03329616039991379, -0.06041023135185242, -0.014874360524117947, 0.020631173625588417, 0.045888543128967285, 0.047797106206417084, -0.05397919937968254, -0.021637318655848503, -0.08119699358940125, -0.045141711831092834, -0.05812825262546539, 0.027798665687441826, 0.0005782744847238064, 0.03771490603685379, -0.013640016317367554, -0.0329434908926487, 0.009470216929912567, -0.009423539973795414, -0.03819204494357109, 0.011472135782241821, -0.03003915399312973, 0.046718351542949677, -0.025703392922878265, 0.05397919937968254, -0.02149210125207901, 0.002756528090685606, -0.032030701637268066, -0.011949276551604271, -0.028172079473733902, -0.02445867657661438, 0.006721468176692724, 0.01685553416609764, 0.02458314783871174, 0.018100250512361526, -0.05642713978886604, -0.030184371396899223, -0.03561963140964508, -0.02149210125207901, -0.0003215517208445817, 0.031097162514925003, -0.009615433402359486, -0.028524748980998993, 0.01919974945485592, -0.05489198863506317, -0.033503614366054535, 0.022301167249679565, 0.042009174823760986, 0.030059900134801865, 0.022114459425210953, 0.050120577216148376, 0.00950133427977562, -0.030620021745562553, -0.0013510358985513449, -0.06186240166425705, -0.012374554760754108, -0.00372118316590786, 0.03329616039991379, -0.04659388214349747, -0.02920934371650219, -0.016077585518360138, 0.01410678494721651, 0.007556465454399586, 0.04817052185535431, 0.007805408909916878, -0.03636646270751953, -0.030848219990730286, -0.021512847393751144, -0.029354561120271683, 0.08430878818035126, 0.0005345148965716362, -0.03922931104898453, -0.0694136843085289, 0.023359175771474838, 0.008728573098778725, -0.016202056780457497, 0.03464460372924805, -0.007566838059574366, -0.009366490878164768, 0.014988459646701813, -0.0060057565569877625, 0.005964265670627356, -0.003013250883668661, 0.024956563487648964, -0.041697997599840164, 0.029831701889634132, -0.0393330380320549, -0.02711407095193863, 0.034250445663928986, 0.0032596008386462927, -0.009594688192009926, 0.0026968854945153, -0.01525814738124609, -0.013494799844920635, -0.026139043271541595, 0.013183620758354664, 0.006602182984352112, 0.009693228639662266, -0.0002850854070857167, -0.005896843504160643, -0.02302725240588188, -0.009947357699275017, -0.006804449483752251, -0.0005089074838906527, 0.03147057816386223, -0.004636568482965231, -0.013577780686318874, 0.020641546696424484, -0.03313019871711731, 0.02707258053123951, -0.02433420531451702, 0.013069521635770798, 0.0053367214277386665, 0.03456162288784981, -0.030848219990730286, 0.006270258687436581, -0.0023195806425064802, -0.01669994369149208, 0.015693798661231995, -0.030142880976200104, -0.03719627484679222, 0.015206284821033478, 0.008365531452000141, -0.003365920390933752, 0.031242379918694496, -0.04472680762410164, -0.03008064441382885, -0.015289265662431717, 0.04642792046070099, 0.016834788024425507, -0.02920934371650219, -0.04688431695103645, 0.014303864911198616, -0.042444828897714615, 0.024956563487648964, -0.02584860846400261, 0.05812825262546539, -0.06020278111100197, 0.034457895904779434, 0.05261000990867615, -0.004138682037591934, -0.0020096981897950172, 3.853272210108116e-05, -0.04217514023184776, -0.02406451664865017, -0.01410678494721651, -0.07231801748275757, 0.07194460183382034, 0.002479060087352991, -0.018266212195158005, 0.04970567300915718, 0.034250445663928986, -0.020361484959721565, -0.013193992897868156, 0.0538962185382843, -0.006036874372512102, 0.007597955875098705, 0.027445994317531586, -0.06717319041490555, -0.020444465801119804, -0.023649610579013824, 0.005590850953012705, 0.02759121172130108, -0.05688353627920151, 0.018473664298653603, -0.002527033444494009, -0.042527809739112854, -0.0179342869669199, 0.008386276662349701, 0.08563648164272308, 0.010398567654192448, -0.03155355900526047, -0.018712235614657402, -0.020050305873155594, -0.06567953526973724, 0.0033996314741671085, -0.019811734557151794, -0.016980005428195, 0.04385550692677498, 0.01418976578861475, -0.032155171036720276, -0.035163234919309616, 0.014615043997764587, -0.0010003111092373729, 0.02228042297065258, -0.01689702458679676, -0.054477084428071976, 0.0824832022190094, 0.07086584717035294, -0.03508025407791138, 0.005736067891120911, -0.00943909864872694, -0.03958198055624962, -0.03082747384905815, 0.01634727418422699, -0.05846017599105835, -0.041303835809230804, -0.06484971940517426, 0.02472836524248123, -0.055348385125398636, 0.05767185613512993, 0.01185592357069254, 0.00019124547543469816, -0.0024181208573281765, 0.008920467458665371, 0.022570855915546417, -0.0007020978373475373, 0.021658064797520638, -0.012986540794372559, -0.020154032856225967, -0.023462902754545212, -0.042486317455768585, -0.007535720244050026, -0.05414516106247902, -0.009983662515878677, -0.02790239080786705, -0.04630344733595848, -0.05568031221628189, -0.0015273706521838903, 0.04356507211923599, 0.04904182255268097, 0.045847050845623016, 0.011523998342454433, 0.002901745028793812, -0.030703002586960793, -0.008152891881763935, 0.00185021897777915, -0.03721701726317406, -0.0004320851294323802, 0.013785233721137047, -0.08219277113676071, -0.010714933276176453, -0.034374915063381195, -0.021232785657048225, 0.031117908656597137, -0.05269299075007439, 0.018546273931860924, 0.030267352238297462, 0.06327307969331741, 0.008484816178679466, -0.025973081588745117, -0.037113290280103683, 0.006171718705445528, -0.0127272242680192, -0.014563181437551975, -0.07903948426246643, 0.03707180172204971, 0.033545106649398804, -0.036822859197854996, -0.03371106833219528, 0.004423929378390312, -0.014220884069800377, -0.03142908588051796, -0.021616574376821518, -0.06372947990894318, -0.04551512748003006, 0.028172079473733902, -0.03624198958277702, -0.03566112369298935, -0.02802686206996441, 0.025309232994914055, 0.016710316762328148, -0.04638642817735672, 0.06468375772237778, 0.06870834529399872, 0.01120244711637497, 0.03978943079710007, 0.004929595161229372, -0.07198609411716461, 0.044270411133766174, -0.00044829235412180424, -0.040391046553850174, -0.05651012063026428, -0.02284054458141327, 0.0383165180683136, 0.023960789665579796, 0.000774057989474386, 0.02240489423274994, 0.031449832022190094, 0.045971523970365524, -0.03978943079710007, 0.008126960135996342, 0.023525139316916466, 0.04294271394610405, 0.006062805652618408, 0.06078364700078964, -0.014065294526517391, -0.005549360532313585, 0.007758731953799725, -0.02671991102397442, -0.003941601607948542, -0.059580422937870026, -0.0008369420538656414, 0.02671991102397442, 0.017903169617056847, -0.011171328835189342, 0.028151335194706917, 0.0037548942491412163, -0.02437569573521614, 0.007136373780667782, -0.02476985566318035, -0.016170939430594444, 0.044270411133766174, -0.03369032219052315, -0.028669966384768486, -0.012530144304037094, -0.06173792853951454, 0.03339988738298416, -0.0751393735408783, 0.03566112369298935, 0.04476829618215561, -0.01788242533802986, -0.05680055543780327, 0.024479420855641365, -0.03964421525597572, 0.013131757266819477, 0.028566239401698112, -0.0008019344531930983, 0.019127141684293747, -0.029976919293403625, -0.009553197771310806, -0.006550319492816925, 0.044145938009023666, 0.05331534892320633, 0.007878017611801624, -0.0592070072889328, 0.044228918850421906, -0.012976167723536491, -0.041096385568380356, 0.020641546696424484, -0.026574693620204926, 0.01726006716489792, -0.00023662576859351248, -0.005204470362514257, -0.015040322206914425, -0.05178019776940346, -0.008230687119066715, 0.009936985559761524, -0.002842102199792862, 0.01229157391935587, 0.012955422513186932, 0.04140756279230118, 0.04866841062903404, -0.07737986743450165, 0.0068822442553937435, 0.0688743069767952, -0.005414516199380159, 0.014283119700849056, -0.03759043291211128, 0.09136217832565308, 0.002945828717201948, 0.034167464822530746, 0.05638565123081207, -0.013992685824632645, 0.007406061980873346, 0.012281200848519802, 0.015164794400334358, 0.02698959968984127, -0.03422969952225685, -0.011835177429020405, 0.031885482370853424, 0.00634286692366004, -0.0005516945966519415, -0.06011980026960373, 0.02541295811533928, -0.0049062566831707954, -0.02271607331931591, 0.036905840039253235, 0.049498219043016434, -0.004299457650631666, 0.01120244711637497, -0.011275055818259716, 0.007675750646740198, -0.010714933276176453, 0.009138292632997036, 0.03126312419772148, -0.031325362622737885, -0.010714933276176453, -0.02564115636050701, -0.033379144966602325, 0.0026385392993688583, -0.000142947887070477, -0.062360286712646484, -0.011067602783441544, -0.019106395542621613, 0.010922386310994625, -0.019697636365890503, 0.01856701821088791, -0.019718380644917488, 0.01788242533802986, -0.045017242431640625, -0.020672664046287537, 0.014967713505029678, 0.011679587885737419, 0.017405282706022263, -0.04821201413869858, -0.01222933828830719, 0.018847079947590828, -0.017042241990566254, 0.010714933276176453, 0.028752947226166725, -0.008277364075183868, 0.05414516106247902, -0.01268573384732008, -0.04269377142190933, 0.004418742842972279, 0.033420633524656296, 0.02350439317524433, 0.0004162020341027528, 0.042527809739112854, -0.026491712778806686, 0.012882813811302185, -0.005290044471621513, 0.007468298077583313, -0.029852446168661118, -0.003031402826309204, -0.03095194697380066, 0.009874749928712845, -0.023919299244880676, -0.048460956662893295, -0.004823275841772556, 0.009729532524943352, 0.012073748745024204, 0.03273604065179825, -0.018909316509962082, 0.025164015591144562, 0.03391851857304573, -0.0524025559425354, 0.03427118808031082, -0.018847079947590828, 0.0717371478676796, -0.011275055818259716, -0.048377975821495056, 0.011544744484126568, -0.031408343464136124, -0.013940823264420033, 0.028234316036105156, 0.02358737401664257, 0.01780981570482254, 0.03684360533952713, 0.015133676119148731, 0.04688431695103645, 5.9723693993873894e-05, 0.0031843993347138166, 0.02358737401664257, 0.03752819821238518, -0.03362808749079704, 0.0392707996070385, 0.021305395290255547, -0.015880506485700607, -0.03142908588051796, -0.0296035036444664, -0.01816248521208763, 0.008858230896294117, 0.01872260868549347, 0.015859760344028473, 0.028047608211636543, -0.005715322680771351, 0.01484324224293232, 0.02354588359594345, 0.006052433047443628, -0.028566239401698112, -0.036553170531988144, -0.0181728582829237, 0.041697997599840164, 0.008562611415982246, -0.012032258324325085, -0.015465600416064262, 0.009563570842146873, 0.009304254315793514, -0.026740655303001404, -0.0066903503611683846, -0.012820578180253506, 0.0005798951606266201, 0.00020761479390785098, 0.03008064441382885, -0.017208203673362732, 0.010196301154792309, -0.007478670682758093, 0.038731422275304794, -0.018535900861024857, 0.005048880819231272, -0.035723358392715454, 0.001510515110567212, -0.010808287188410759, -0.024085260927677155, 0.0019578351639211178, 0.008832300081849098, 0.08430878818035126, -0.01563156209886074, 0.04149054363369942, -0.010891268029808998, -0.0758032277226448, -0.012986540794372559, -0.007323081139475107, 0.01438684668391943, -0.01076679676771164, -0.026035316288471222, 0.005248554050922394, 0.010932758450508118, -0.03578559309244156, 0.03379404917359352, -0.010128878988325596, 0.0013244559522718191, -0.03304721787571907, 0.010408940725028515, 0.007805408909916878, 0.003949381411075592, -0.029188597574830055, -0.03844099119305611, 0.014573553577065468, -0.0052304016426205635, -0.019293103367090225, -0.00416461331769824, -0.03510100021958351, 0.027570467442274094, 0.0018191010458394885, 0.011368408799171448, -0.015932369977235794, 0.023483648896217346, -0.01769571751356125, -0.007706868462264538, 0.05343982204794884, 0.022384148091077805, 0.04188470542430878, -0.008069911040365696, -0.013557035475969315, -0.03269454836845398, 0.02228042297065258, 0.012810206040740013, 0.011015739291906357, -0.04638642817735672, 0.03871067985892296, 0.0023986720480024815, 0.019998442381620407, 0.049249276518821716, 0.04385550692677498, -0.01724969409406185, -0.02105645090341568, -0.02090086229145527, -0.050286538898944855, 0.019811734557151794, 0.004937374964356422, 0.016565099358558655, 0.021637318655848503, 0.022467130795121193, -0.07252547144889832, 0.01816248521208763, 0.033462125808000565, -0.028835928067564964, -0.00528226513415575, -0.0751393735408783, -0.014957341365516186, 0.02136762998998165, -0.04555661976337433, -0.03765266761183739, 0.029188597574830055, -0.028586985543370247, 0.010144438594579697, 0.014003058895468712, -0.027051834389567375, -0.02968648448586464, -0.018141740933060646, 0.05219510570168495, -0.008889349177479744, -0.012519772164523602, -0.004115343559533358, -0.02288203500211239, 0.000614902819506824, -0.02097347006201744, -0.01199076697230339, 0.04146979749202728, -0.009656923823058605, 0.051157839596271515, -0.025973081588745117, 0.010953503660857677, -0.049332257360219955, -0.030723748728632927, -0.02976946532726288, -0.014345355331897736, -0.01440759189426899, -0.0060057565569877625, -0.031180143356323242, -0.045058730989694595, -0.009148664772510529, -0.03898036479949951, -0.00035299378214403987, 0.029064126312732697, -0.012301946058869362, -0.024915071204304695, -0.009890308603644371, 0.06908175349235535, -0.009221273474395275, -0.04460233449935913, -0.0050307284109294415, -0.027321523055434227, -0.020205894485116005, 0.00013387182843871415, -0.0215750839561224, 0.03122163563966751, 0.04016284644603729, -0.02029924839735031, 0.03012213483452797, 0.00018751781317405403, 0.0022430825047194958, 0.015932369977235794, -0.05099187791347504, 0.011326918378472328, -0.003303684527054429, 0.03680211305618286, -0.029375305399298668, 0.00043143684160895646, -0.011420272290706635, 0.014998831786215305, 0.005855353083461523, 0.015724916011095047, -0.026533203199505806, 0.028130589053034782, 0.02394004352390766, 0.001950055593624711, 0.010621579363942146, 0.0019396829884499311, 0.0024985086638480425, 0.004950340371578932, -0.027300778776407242, -0.0032414488960057497, 0.014449082314968109, 0.033379144966602325, -0.014812123961746693, -0.0065088290721178055, 0.001650545746088028, 0.04622046649456024, -0.0018398463726043701, 0.0071674915961921215, -0.05505795404314995, -0.006737027317285538, 0.03622124716639519, 0.013266601599752903, -0.023172469809651375, -0.022301167249679565, -0.0017633481184020638, -0.009304254315793514, -0.024396440014243126, 0.03039182350039482, 0.03835800662636757, -0.011046857573091984, -0.028006117790937424, -0.0058138626627624035, 0.02458314783871174, -0.04663537070155144, -0.005803490057587624, -0.015372246503829956, 0.013546662405133247, 0.0033399888779968023, 0.013805978931486607, 0.003218110417947173, -0.0032777530141174793, 0.04389699548482895, 0.008853045292198658, 0.050286538898944855, 0.0398101769387722, 0.06211134418845177, 0.0105489706620574, -0.017633480951189995, 0.05269299075007439, -0.05402068793773651, -0.03360734134912491, 0.03750745207071304, -0.012094493955373764, -0.017633480951189995, 0.05256852135062218, -0.022570855915546417, -0.03740372508764267, -0.010237791575491428, -0.003008064581081271, -0.006768145132809877, -0.01658584550023079, 0.03632497042417526, 0.0004194434732198715, -0.006529574282467365, -0.012053003534674644, 0.04447786509990692, -0.017145967110991478, -0.02085937187075615, 0.02715556137263775, -0.036034539341926575, 0.005456006620079279, 0.08837486058473587, 0.021741045638918877, 0.039042603224515915, 0.0007053392473608255, 0.04032880812883377, 0.0010631951736286283, -0.020351111888885498, -0.011814432218670845, -0.03234187886118889, 0.03723776340484619, -0.015890877693891525, 0.0074527389369904995, 0.0025957522448152304, 0.020911235362291336, -0.04032880812883377, -0.002829136559739709, -0.02030962146818638, 0.019500555470585823, -0.024873580783605576, -0.007193423341959715, -0.0363457165658474, 0.008287736214697361, 0.02864922024309635, -0.011264682747423649, 0.07638408988714218, 0.01527889259159565, 0.021191295236349106, -0.01769571751356125, 0.024043770506978035, -0.008899722248315811, 0.01367113459855318, 0.03922931104898453, 0.04120011255145073, -0.0199050884693861, 0.03705105558037758, -0.019884344190359116, 0.0013562222011387348, 0.025475194677710533, 0.0012602752540260553, 0.018193604424595833, 0.033586595207452774, 0.059497442096471786, -0.017042241990566254, -0.019956951960921288, -0.01876409910619259, -0.028607729822397232, -0.005824235267937183, 0.025309232994914055, -0.012499026954174042, -0.01650286465883255, 0.014573553577065468, -0.09443248063325882, 0.02829655073583126, -0.04010061174631119, 0.021077197045087814, -0.010175555944442749, -0.013764488510787487, 0.029541267082095146, -0.054601557552814484, 0.048419464379549026, -0.0035422551445662975, -0.037735648453235626, 0.013121385127305984, -0.014656534418463707, 0.032715294510126114, 0.04576407000422478, -0.021201668307185173, 0.011472135782241821, -0.003913077060133219, 0.012343437410891056, -0.023089488968253136, -0.031242379918694496, -0.016482118517160416, -0.04261079058051109, -0.020848998799920082, 0.02362886443734169, 0.018712235614657402, 0.01582864299416542, 0.017975779250264168, -0.042092155665159225, 0.016046468168497086, 0.02750823087990284, -0.0004771412641275674, -0.024956563487648964, 0.013256228528916836, -0.062277305871248245, 0.015465600416064262, 0.027300778776407242, -0.0858854278922081, -0.005513056181371212, -0.010263723321259022, -0.010994994081556797, -0.001542929676361382, 0.0051733520813286304, 0.030744493007659912, 0.03207219019532204, -0.04634493961930275, -0.05937296897172928, -0.03657391667366028, 0.025267742574214935, 0.003093638690188527, -0.011783314868807793, 0.012053003534674644, -0.014210511930286884, -0.006047246977686882, 0.001485880115069449, -0.01333921030163765, 0.009231646545231342, 0.009828072972595692, -0.0804501622915268, 0.00039480847772210836, -0.03532920032739639, -0.015040322206914425, -0.0077016823925077915, -0.03696807473897934, 0.0075201611034572124, 0.029375305399298668, 0.007950625382363796, 0.012042630463838577, 0.055223915725946426, 0.008894535712897778, -0.07352124154567719, 0.02671991102397442, -0.0023558849934488535, 0.03155355900526047, 0.02101496048271656, 0.06684126704931259, 0.007105255965143442, -0.012841323390603065, 0.012333064340054989, 0.0009594688308425248, -0.06115706264972687, 0.006130227819085121, -0.014915850944817066, -0.015434482134878635, -0.0127272242680192, 0.0036044910084456205, -0.010839404538273811, 0.007623887620866299, 0.021948497742414474, 0.017602363601326942, -0.02196924388408661, 0.03122163563966751, 0.015839016065001488, 0.010797914117574692, -0.024998053908348083, 0.028524748980998993, -0.03723776340484619, -0.023525139316916466, -0.04198843240737915, 0.06306562572717667, 0.007489043287932873, 0.0063480534590780735, -0.018421802669763565, 0.045805562287569046, -0.008199568837881088, 0.02916785329580307, 0.020434092730283737, -0.0011617352720350027, -0.016834788024425507, -0.001218784716911614, -0.04364805296063423, 0.0031818060670048, -0.06032725051045418, 0.04970567300915718, -0.00955838430672884, -0.0009711380698718131, -0.05480900779366493, -0.019573165103793144, 0.0025101779028773308, -0.029375305399298668, 0.019044160842895508, -0.025122525170445442, -0.025993825867772102, 0.010144438594579697, -0.03317169100046158, -0.05244404822587967, -0.00026968854945153, 0.018930060788989067, 0.03344137966632843, 0.03487280383706093, -0.01473951619118452, 0.024832090362906456, -0.0002144218306057155, 0.03866918757557869, 0.026305004954338074, -0.03549516201019287, 0.016160566359758377, 0.019656145945191383, -0.003233669325709343, 0.011409900151193142, -0.0431501679122448, 0.03207219019532204, -0.05236106738448143]\n"
     ]
    }
   ],
   "source": [
    "# 문서 컬렉션\n",
    "documents = [\n",
    "    \"인공지능은 컴퓨터 과학의 한 분야입니다.\",\n",
    "    \"머신러닝은 인공지능의 하위 분야입니다.\",\n",
    "    \"딥러닝은 머신러닝의 한 종류입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.\",\n",
    "    \"컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 방법을 연구합니다.\"\n",
    "]\n",
    "\n",
    "# 문서 임베딩\n",
    "document_embeddings_openai = embeddings_openai.embed_documents(documents)\n",
    "\n",
    "# 임베딩 결과 출력\n",
    "print(f\"임베딩 벡터의 개수: {len(document_embeddings_openai)}\")\n",
    "print(f\"임베딩 벡터의 차원: {len(document_embeddings_openai[0])}\")\n",
    "print(document_embeddings_openai[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adef264",
   "metadata": {},
   "source": [
    "`(3) embed_query 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "668fd5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리 임베딩 벡터의 차원: 1024\n",
      "[-0.026167644187808037, 0.025727111846208572, 0.0005699392058886588, 0.006574951112270355, 0.014141100458800793, -0.05198286101222038, -0.030484864488244057, 0.041542235761880875, -0.0030672091525048018, 0.017169762402772903, -0.0024366965517401695, 0.001000146963633597, -0.005644325632601976, -0.08537524193525314, 0.010462651960551739, -0.01789664290845394, -0.069383904337883, -0.026035483926534653, 0.026013458147644997, -0.08030911535024643, -0.03389899432659149, 0.026960602030158043, -0.04275370016694069, 0.004777026828378439, 0.012929635122418404, -0.061057835817337036, 0.012445049360394478, -3.5900837247027084e-05, -0.0125331562012434, -0.03955983743071556, 0.02933947928249836, -0.02193853072822094, -0.0017401042860001326, -0.06841473281383514, 0.05788600072264671, -0.0039620413444936275, -0.0032021221704781055, -0.009708239696919918, -0.005333199165761471, 0.02645399048924446, -0.013788674026727676, 0.044053271412849426, 0.00382712809368968, 0.04083738476037979, -0.05964813008904457, 0.040000371634960175, -0.03310603275895119, 0.005443332716822624, -0.015627898275852203, 0.044780150055885315, -0.052643660455942154, 0.0400884784758091, -0.008931800723075867, -0.010842612013220787, -0.0033838420640677214, 0.07497867196798325, 0.01326003484427929, 0.036498136818408966, -0.006888830568641424, 0.054846324026584625, -0.00040198612259700894, -0.004245634190738201, 0.019218239933252335, 0.04533081874251366, -0.07224737107753754, -0.023854847997426987, -0.0032021221704781055, 0.04110170528292656, -0.043744899332523346, -0.024779966101050377, 0.048018068075180054, 0.002406409941613674, -0.08370121568441391, -0.006145431660115719, -0.02281959541141987, 0.016178565099835396, -0.024163220077753067, 0.05044099688529968, -0.0009774320060387254, 0.014251234009861946, 0.022643381729722023, 0.010660892352461815, 0.0014661479508504272, -0.0512780100107193, -0.011365744285285473, -0.01951560005545616, -0.024009034037590027, -0.06277591735124588, -0.06061730161309242, -3.787979221669957e-05, -0.02181738242506981, 0.07149846106767654, -0.029207319021224976, 0.03638800233602524, -0.023105941712856293, 0.04568324238061905, 0.09110216796398163, -0.010170799680054188, 0.01266531553119421, 0.02748924307525158, -0.0370047502219677, 0.004509953781962395, 0.019416479393839836, 0.039647944271564484, 0.028039908036589622, -0.0670931339263916, -0.01985701359808445, 0.03319413959980011, 0.03281968832015991, 0.012323902919888496, 0.024934152141213417, 0.011288651265203953, -0.09788636863231659, 0.04301802068948746, -0.024009034037590027, -0.002312796888872981, 0.008392148651182652, -0.023194048553705215, -0.014867980033159256, -0.04392111301422119, -0.033832915127277374, -0.013116861693561077, 0.03189456835389137, -0.0026032731402665377, -0.03559504449367523, -0.033987101167440414, -0.0030038824770599604, -0.03594747185707092, -0.02779761515557766, -0.011641077697277069, -0.015870191156864166, 0.029581772163510323, -0.03539680317044258, 0.008777614682912827, 0.02625575102865696, -0.08317258208990097, 0.02594737708568573, 0.04475812613964081, -0.01392083428800106, -0.05533090978860855, 0.014779873192310333, -0.0020181904546916485, -0.027665454894304276, -0.002406409941613674, -0.03123377077281475, -0.048634812235832214, -0.0022852635011076927, -0.017819548025727272, -0.0010345635237172246, -0.006255564745515585, -0.06674070656299591, -0.009218147024512291, -0.04982425272464752, -0.03451573848724365, -0.04920750483870506, 0.041586291044950485, -0.013788674026727676, 0.042048849165439606, -0.0008893254562281072, -0.004788040183484554, -0.040308743715286255, 0.001887407386675477, -0.008849200792610645, -0.003425142029300332, -0.06700503081083298, 0.06982443481683731, -0.027467215433716774, 0.0038161147385835648, 0.019570667296648026, -0.0069053503684699535, -0.0628199651837349, -0.0030727158300578594, -0.021189624443650246, 0.009300746954977512, -0.001023550285026431, -0.024801991879940033, 0.02144293114542961, 0.001121981767937541, -0.008133335039019585, -0.05867895856499672, -0.05903138592839241, -0.0427977554500103, -0.04233519360423088, 0.02136583812534809, -0.04022063687443733, 0.01700456254184246, -0.03041878528892994, -0.014956085942685604, 0.0021255703177303076, 0.02175130322575569, 0.01950458623468876, 0.05030883848667145, 0.03978010639548302, 0.03215888887643814, 0.006883323658257723, -0.02429538033902645, -0.002465606667101383, -0.01243403647094965, 0.033987101167440414, 0.018260082229971886, 0.050176676362752914, -0.057004936039447784, 0.02702668309211731, -0.00513771316036582, 0.00699896365404129, 0.02429538033902645, 0.06185079365968704, -0.011288651265203953, -0.04845859855413437, -0.006773190572857857, 0.026894522830843925, -0.022687435150146484, 0.08233556896448135, -0.05493443086743355, -0.01962573267519474, -0.020110318437218666, 0.025154419243335724, 0.03191659599542618, -0.044780150055885315, 0.0331500880420208, -0.03909727931022644, 0.004485173616558313, -0.026938576251268387, 0.004424600396305323, -0.026387911289930344, 0.010143266059458256, 0.01389880757778883, -0.04094751551747322, 0.026960602030158043, -0.04330436885356903, -0.035330723971128464, -0.026960602030158043, 0.0069053503684699535, -0.01121706422418356, -0.028744760900735855, -0.021795356646180153, -0.012092622928321362, -0.0013071432476863265, 0.01789664290845394, 0.012940648943185806, 0.015253446064889431, 0.03806202858686447, -0.014174140058457851, 0.0030341690871864557, 0.005278132855892181, 0.012852542102336884, 0.02768748253583908, 0.030991477891802788, -0.007351390086114407, -0.019339386373758316, 0.008518802002072334, -0.043546661734580994, 0.04094751551747322, -0.007312843110412359, 0.003772061550989747, -0.0035270152147859335, 0.028943000361323357, 0.03466992452740669, 0.0021971568930894136, 0.02513239160180092, -0.01464771293103695, 0.027621401473879814, -0.027863694354891777, -0.02933947928249836, 0.005914151668548584, 0.0027134062256664038, 0.029097186401486397, 0.03607963025569916, -0.008304041810333729, -0.046167828142642975, -0.04815022647380829, 0.012753422372043133, 0.01962573267519474, -0.02451564557850361, -0.02522049844264984, 0.014284273609519005, 0.005495645571500063, 0.0037472816184163094, -0.033876966685056686, 0.04363476485013962, -0.05035289004445076, -0.01245606318116188, 0.047092948108911514, -0.02301783487200737, 0.014460486359894276, 0.006767684128135443, -0.012400995939970016, -0.07317248731851578, -0.06612396240234375, -0.0347139798104763, 0.08669684082269669, -0.002552336547523737, 0.010236878879368305, 0.033260222524404526, 0.03251131623983383, -0.008915280923247337, 0.03262144699692726, 0.05682872235774994, -0.01054525189101696, 0.016101472079753876, 0.10105820745229721, -0.04213695600628853, -0.07801834493875504, -0.054229579865932465, -0.03334832936525345, 0.0694279596209526, -0.05339256674051285, 0.013116861693561077, 0.0033976086415350437, -0.03345846012234688, 0.031101610511541367, 0.03982415795326233, 0.043546661734580994, -0.028832867741584778, -0.009818373247981071, -0.03440560773015022, 0.0071806833148002625, -0.022533249109983444, 0.05061721056699753, 0.0038381414487957954, -0.002221937058493495, -0.008728054352104664, -0.005209299735724926, -0.02112354338169098, -0.0435686856508255, -0.010644371621310711, 0.011960463598370552, -0.0026748597156256437, -0.02995622530579567, -0.019053040072321892, 0.04577134922146797, 0.050837475806474686, -0.03334832936525345, -0.013909820467233658, -0.01530851237475872, -0.010479172691702843, -0.036608271300792694, 0.0163878183811903, -0.05339256674051285, -0.048326440155506134, -0.05656440183520317, 0.030969450250267982, -0.067842036485672, 0.03273158147931099, 0.04594756290316582, -0.008849200792610645, -0.036255843937397, -0.0006680265651084483, 0.00037479697493836284, 0.036189764738082886, 0.044780150055885315, -0.03125579655170441, -0.008612414821982384, -0.06220322102308273, -0.03925146535038948, 0.001121981767937541, -0.0075936829671263695, 0.0005341459182091057, -0.02460375241935253, -0.035991523414850235, -0.09841500967741013, -0.0323791541159153, 0.03484613820910454, 0.049648039042949677, 5.614211113424972e-05, 0.005019319709390402, 0.01827109418809414, -0.023898901417851448, -0.007979148998856544, -0.029757985845208168, -0.007445002906024456, -0.018138935789465904, 0.030440811067819595, -0.05370093882083893, -0.00827100221067667, -0.003568315180018544, -0.011905397288501263, 0.030550945550203323, -0.022885674610733986, 0.03292982280254364, 0.020022211596369743, 0.04288586229085922, -0.02297378145158291, -0.07418571412563324, -0.025506844744086266, 0.021982582286000252, 0.010815078392624855, -0.043084099888801575, -0.051410168409347534, 0.05656440183520317, 0.04568324238061905, -0.04160831496119499, -0.02872273325920105, -0.01187235675752163, -0.07352491468191147, 0.00280426605604589, -0.03345846012234688, -0.03821621462702751, -0.018403254449367523, 0.003917987924069166, -0.017180776223540306, -0.0022398335859179497, -0.010688425041735172, -0.041542235761880875, -0.0022742501460015774, -0.054229579865932465, 0.037026774138212204, 0.049339666962623596, -0.0015418645925819874, 0.06819446384906769, 0.05788600072264671, -0.03191659599542618, 0.05180664733052254, -0.0034499219618737698, -0.014856966212391853, -0.040969543159008026, 0.009108014404773712, 0.001557007897645235, 0.01338118128478527, 0.007323856465518475, 0.03185051679611206, -0.010721465572714806, -0.01666315086185932, -0.06259970366954803, -0.005770978517830372, 0.010693931952118874, 0.03557301685214043, 0.019868025556206703, 0.08409769833087921, -0.04731321334838867, 0.029824065044522285, 0.04449380561709404, -0.027092762291431427, -0.025727111846208572, -0.0593838132917881, 0.012775449082255363, 0.03107958473265171, -0.015594858676195145, 0.020848210901021957, 0.04268762096762657, -0.017599282786250114, -0.029890146106481552, 0.006943897344172001, -0.03590341657400131, -0.06299617886543274, 0.03041878528892994, -0.05105774477124214, 0.005198286380618811, -0.023722687736153603, -0.09392157942056656, -0.010572785511612892, -0.03156416863203049, 0.04017658531665802, 0.0666966587305069, -5.0076181651093066e-05, -0.060749463737010956, 0.016200590878725052, -0.0147468326613307, 0.018072854727506638, 0.0192733071744442, -0.04090346395969391, -0.019328372552990913, -0.008529814891517162, 0.05149827525019646, -0.006084858439862728, -0.005815031938254833, 0.008876734413206577, 0.013667527586221695, -0.03995632007718086, -0.0036178750451654196, -0.09277619421482086, -0.05585955083370209, 0.056960880756378174, -0.029427586123347282, 0.014119073748588562, 0.047137003391981125, 0.02455969899892807, -0.034758031368255615, -0.03982415795326233, 0.01592525839805603, 0.01530851237475872, -0.02105746418237686, 0.021288743242621422, 0.0004911251598969102, 0.05255555361509323, 0.042048849165439606, -0.07735754549503326, -0.013909820467233658, 0.053304459899663925, -0.01715875044465065, -0.02676236256957054, -0.03453776612877846, 0.07907562702894211, -0.0015446179313585162, 0.06277591735124588, 0.025506844744086266, 0.010000092908740044, -0.04938371852040291, -0.002749199513345957, 0.0027010163757950068, 0.003185602370649576, -0.02938353270292282, -0.030440811067819595, 0.055507123470306396, -0.0125331562012434, -0.018766693770885468, 0.003739021485671401, 0.023964980617165565, -0.0235244482755661, -0.029097186401486397, -0.00560853211209178, 0.019174186512827873, 0.008783121593296528, 0.0069383904337882996, 0.004801806528121233, 0.022797567769885063, 0.0007282556616701186, 0.04290788620710373, 0.03685056418180466, -0.01692746952176094, 0.003480208572000265, 0.01592525839805603, -0.014625686220824718, -0.0023183035664260387, -0.0037665548734366894, -0.04788590595126152, -0.04321626201272011, -0.007995668798685074, -0.008838187903165817, -0.030286625027656555, 0.006800724193453789, -0.006057324819266796, 0.01108490489423275, -0.008590388111770153, -0.030947424471378326, 0.009399866685271263, 0.03211483731865883, 0.02144293114542961, -0.02297378145158291, 0.03211483731865883, 0.019923092797398567, 0.013986914418637753, 0.007511083036661148, -0.005765472073107958, 0.00121972500346601, 0.010033132508397102, -0.009355814196169376, -0.05224718153476715, -0.01900898665189743, 0.06427372246980667, 0.04599161818623543, 0.010424105450510979, 0.030132438987493515, -0.0435686856508255, 0.04063914343714714, 0.01592525839805603, -0.0037610481958836317, -0.007968136109411716, -0.0015446179313585162, -0.008909774012863636, -0.0034361553844064474, -0.016398830339312553, -0.03403115272521973, -0.022797567769885063, -0.008243468590080738, -0.017874615266919136, 0.026652229949831963, -0.03242320939898491, 0.024185245856642723, 0.023260127753019333, -0.05956002324819565, 0.014680753462016582, -0.0006773190689273179, 0.052379339933395386, -0.024339433759450912, -0.02753329463303089, 0.024779966101050377, -0.04643214866518974, 0.003425142029300332, 0.054185524582862854, 0.0050413464196026325, 0.002815279411152005, -0.005622298922389746, 0.009388853795826435, 0.04233519360423088, 0.004633853677660227, -0.016861390322446823, 0.03821621462702751, 0.02363458089530468, -0.0015198378823697567, 0.033987101167440414, -0.0006122716586105525, 0.008436202071607113, -0.053965259343385696, -0.005699391942471266, -0.0009540286846458912, 0.01513229962438345, -0.0010125369299203157, -0.021420903503894806, 0.04638809710741043, 0.008628934621810913, 0.012786461971700191, 0.011398783884942532, 0.007538616191595793, -0.02425132691860199, -0.024383487179875374, -0.00382712809368968, 0.028965026140213013, 0.026057511568069458, -0.043744899332523346, -0.013006729073822498, -0.0027973828837275505, 0.00022112678561825305, -0.025000233203172684, -0.05061721056699753, -0.01033049263060093, -0.00905845407396555, 0.020561864599585533, 0.05374499410390854, -0.025616977363824844, -0.023876873776316643, -0.01580411195755005, 0.054493896663188934, -0.012522142380475998, -0.014262246899306774, -0.023700660094618797, -0.007913068868219852, -0.002454593311995268, -0.03940565139055252, -0.004515460692346096, 0.00281390268355608, 0.0797804743051529, -0.028172068297863007, 0.01052322518080473, 0.008050736039876938, -0.05740141496062279, -0.013755634427070618, -0.01703760400414467, 0.03281968832015991, -0.017841575667262077, -0.035639096051454544, 0.01803981512784958, 0.02144293114542961, -0.03502235189080238, 0.017676375806331635, -0.018105894327163696, -0.033568594604730606, -0.014086034148931503, 0.015782084316015244, -0.017103683203458786, -0.01451555360108614, -0.04594756290316582, -0.038194186985492706, -0.008617921732366085, 0.024581726640462875, -0.00313328905031085, -0.004925706423819065, -0.01888784021139145, 0.03273158147931099, -0.02109050378203392, 0.009443920105695724, -0.017224829643964767, 0.02013234607875347, 0.008182895369827747, -0.00973577331751585, 0.03878890722990036, 0.055419016629457474, 0.02517644502222538, 0.03693867102265358, -0.013733607716858387, -0.05625602975487709, -0.016630111262202263, -0.010347012430429459, 0.013557394966483116, -0.019416479393839836, 0.019956132397055626, -0.035837337374687195, 0.006090364884585142, 0.01754421554505825, 0.011453851126134396, -0.004606320522725582, 0.0068668038584291935, -0.026321830227971077, -0.018414268270134926, 0.0294936653226614, 0.042467355728149414, 0.04722511023283005, 0.02193853072822094, -0.0034361553844064474, -0.06859094649553299, 0.002198533620685339, 0.029207319021224976, 0.002732679480686784, 0.004253894090652466, -0.04444975405931473, 0.032863739877939224, 0.0007984655676409602, 0.006316137965768576, -0.03751136362552643, 0.039273492991924286, -0.014658726751804352, 0.044736098498106, 0.018293121829628944, -0.0377977080643177, -0.009498987346887589, -0.012246809899806976, 0.028083961457014084, -0.013524354435503483, 0.020418692380189896, 0.011696144007146358, -0.029824065044522285, 0.0037665548734366894, 0.012367956340312958, -0.01735698990523815, 0.02652006968855858, 0.026057511568069458, 0.04422948509454727, 0.0013305464526638389, -0.006987950298935175, -0.029735960066318512, -0.015627898275852203, -0.007406456395983696, 0.0021035438403487206, -0.014207180589437485, 0.0026018964126706123, -0.022885674610733986, -0.06026487797498703, -0.009449427016079426, -0.026630204170942307, -0.027268975973129272, -0.004542993847280741, -0.03418533876538277, -0.02625575102865696, 0.005357979331165552, 0.0647583082318306, -0.021035438403487206, -0.046784576028585434, 0.0020126840099692345, -0.05872301384806633, 0.00450169388204813, 0.036498136818408966, -0.00773134920746088, 0.03596949577331543, -0.031145663931965828, -0.02676236256957054, 0.02078213170170784, -0.013403207994997501, 0.038194186985492706, 0.03299590200185776, -0.02155306376516819, -0.0025234264321625233, 0.000127341496408917, 0.02089226432144642, 0.0018819007091224194, 0.012995715253055096, 0.0250663124024868, 0.01750016212463379, -0.03641002997756004, 0.029559746384620667, 0.010214852169156075, 0.017368003726005554, -0.007830468937754631, 0.012059583328664303, 0.029361506924033165, -0.0016272177454084158, 0.0008913904312066734, 0.017456108704209328, 0.01106838509440422, 0.016685176640748978, 0.032709553837776184, -0.0022370803635567427, -0.01911912113428116, 0.026123590767383575, 0.01989005319774151, 0.04643214866518974, 0.007681789342314005, -0.006382218096405268, -0.041035622358322144, -0.015605871565639973, 0.03433952480554581, -0.008342588320374489, -0.0033976086415350437, -0.004468653816729784, 0.0022233135532587767, -0.004113474395126104, 0.0030754690524190664, 0.02243412844836712, 0.00908048078417778, -0.006657551042735577, -0.019405467435717583, -0.012191743589937687, 0.03057297132909298, -0.003463688539341092, -0.031013503670692444, -0.00696041714400053, 0.017764482647180557, 0.008937307633459568, 0.02383282035589218, 0.012764436192810535, -0.024779966101050377, 0.024339433759450912, 0.02568305842578411, 0.019185200333595276, 0.056432243436574936, 0.02845841459929943, 0.007758882828056812, -0.02035261131823063, 0.03903120011091232, -0.022775541990995407, -0.04028671979904175, 0.02537468448281288, 0.00962013378739357, -0.0281500406563282, 0.024031059816479683, -0.02784166857600212, -0.02707073651254177, -0.009465946815907955, -0.00489817326888442, -0.009967053309082985, -0.01513229962438345, 0.0462559349834919, -0.0030892358627170324, 0.03231307491660118, -0.007725842762738466, 0.04691673442721367, 0.020727064460515976, -0.03389899432659149, -0.014713793061673641, -0.030903371050953865, 0.004721960052847862, 0.0724676325917244, 0.025859270244836807, 0.033061981201171875, 0.00017999892588704824, 0.030683103948831558, 0.013293075375258923, -0.021872449666261673, -0.02922934666275978, -0.03654218837618828, 0.015066219493746758, -0.03242320939898491, 0.012048570439219475, -0.015980323776602745, 0.06453804671764374, -0.025264551863074303, 0.022257916629314423, -0.011051864363253117, 0.0026376897003501654, 0.027973828837275505, -0.015198378823697567, -0.02614561654627323, -0.00529189920052886, 0.06343670934438705, 0.006943897344172001, 0.04160831496119499, 0.00551491929218173, 0.014207180589437485, -0.01711469702422619, -0.003521508537232876, -0.030837291851639748, -0.006982443854212761, 0.04226911440491676, 0.045286763459444046, 0.011773237027227879, 0.025000233203172684, -0.008920787833631039, -0.01569397933781147, -0.005815031938254833, -0.012290863320231438, -0.0069383904337882996, 0.03720298781991005, 0.038260266184806824, -0.026784390211105347, -0.03006635792553425, 0.028128014877438545, -0.007687296252697706, 0.0007970888982526958, 0.07837077230215073, -0.0103139728307724, -0.023876873776316643, 0.014912032522261143, -0.05405336618423462, 0.004347507376223803, -0.0385466143488884, -0.042665593326091766, -0.02144293114542961, 0.005897631868720055, 0.033921018242836, -0.023546474054455757, 0.028965026140213013, 0.003973054699599743, -0.018403254449367523, 0.021002396941184998, -0.032599423080682755, 0.02374471351504326, 0.041233863681554794, 0.01924026757478714, 0.030947424471378326, -0.005300159566104412, -0.008017695508897305, -0.00010058256884803995, -0.044978391379117966, -0.0111785177141428, -0.02044071815907955, -0.013425234705209732, 0.03898714482784271, 0.0304628387093544, 0.05066126212477684, 0.022147782146930695, -0.026784390211105347, -0.012940648943185806, 0.021024424582719803, 0.02671830914914608, -0.030396757647395134, -0.0061399247497320175, -0.030330678448081017, -0.012698356062173843, 0.012400995939970016, -0.04889913275837898, -0.06793014705181122, 0.023194048553705215, 0.027158843353390694, 0.011211558245122433, 0.014295287430286407, 0.006696097552776337, 0.017334962263703346, -0.03411925956606865, -0.03334832936525345, -0.014030967839062214, 0.012962675653398037, -0.019603706896305084, -0.02737910859286785, -0.018171975389122963, 0.013931847177445889, 0.022268928587436676, 0.00459806015715003, -0.03334832936525345, 0.0029791025444865227, -0.0006057324935682118, -0.08141044527292252, 0.0029102694243192673, -0.030220545828342438, -0.014912032522261143, -0.01123909093439579, -0.04090346395969391, -0.002406409941613674, 0.021795356646180153, 0.031145663931965828, 0.0014702780172228813, 0.04244532808661461, 0.04226911440491676, -0.07572757452726364, 0.031476061791181564, 0.007902055978775024, 0.017489150166511536, -0.010737985372543335, 0.07035307586193085, 0.01256619580090046, -0.011641077697277069, -0.001167411683127284, 0.012797475792467594, -0.025815218687057495, 0.005357979331165552, -0.029317453503608704, 0.009911986067891121, -0.006767684128135443, 0.007924082688987255, 0.02497820556163788, 0.0013745997566729784, 0.02636588364839554, -0.029757985845208168, 0.006894337013363838, 0.036806508898735046, 0.01199350319802761, 0.012169716879725456, 0.008838187903165817, 0.032026730477809906, -0.015793098136782646, -0.0072798035107553005, -0.003887701313942671, 0.03944970667362213, -0.003978561144322157, -0.0002966712636407465, -0.021795356646180153, 0.033414408564567566, 0.03482411056756973, 0.021916503086686134, 0.02733505517244339, -0.009278720244765282, 0.013469288125634193, 0.0023086669389158487, -0.07282005995512009, 0.029449613764882088, -0.02475793845951557, 0.06118999421596527, -0.023260127753019333, -0.003557301824912429, -0.03453776612877846, 0.015000139363110065, -0.026982629671692848, 0.013094834983348846, 0.056652508676052094, -0.003810608061030507, -0.01700456254184246, -0.02312796749174595, -0.0424233004450798, -0.027401136234402657, -0.022643381729722023, -0.015198378823697567, 0.02275351621210575, 0.03801797330379486, 0.028039908036589622, 0.028502468019723892, 0.0004887160030193627, 0.03057297132909298, 0.03193862363696098, -0.05105774477124214, -0.012213770300149918, 0.037070829421281815, 0.0004116227792110294, 0.01908607967197895, 0.0037527880631387234, 0.045595135539770126, -0.040198612958192825]\n"
     ]
    }
   ],
   "source": [
    "embedded_query_openai = embeddings_openai.embed_query(\"인공지능이란 무엇인가요?\")\n",
    "\n",
    "# 쿼리 임베딩 결과 출력\n",
    "print(f\"쿼리 임베딩 벡터의 차원: {len(embedded_query_openai)}\")\n",
    "print(embedded_query_openai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63d0f4",
   "metadata": {},
   "source": [
    "`(4) 유사도 기반 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7029f9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 인공지능이란 무엇인가요?\n",
      "가장 유사한 문서: 인공지능은 컴퓨터 과학의 한 분야입니다.\n",
      "유사도: 0.7147\n",
      "\n",
      "쿼리: 딥러닝과 머신러닝의 관계는 어떻게 되나요?\n",
      "가장 유사한 문서: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "유사도: 0.6752\n",
      "\n",
      "쿼리: 컴퓨터가 이미지를 이해하는 방법은?\n",
      "가장 유사한 문서: 컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 방법을 연구합니다.\n",
      "유사도: 0.7050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 쿼리와 가장 유사한 문서 찾기 함수\n",
    "def find_most_similar(\n",
    "        query: str, \n",
    "        doc_embeddings: np.ndarray,\n",
    "        embeddings_model=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        ) -> tuple[str, float]:\n",
    "    \n",
    "    # 쿼리 임베딩: OpenAI 임베딩 사용 \n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "\n",
    "    # 가장 유사한 문서 인덱스 찾기\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "\n",
    "    # 가장 유사한 문서와 유사도 반환: 문서, 유사도\n",
    "    return documents[most_similar_idx], similarities[most_similar_idx]\n",
    "\n",
    "# 예제 쿼리\n",
    "queries = [\n",
    "    \"인공지능이란 무엇인가요?\",\n",
    "    \"딥러닝과 머신러닝의 관계는 어떻게 되나요?\",\n",
    "    \"컴퓨터가 이미지를 이해하는 방법은?\"\n",
    "]\n",
    "\n",
    "# 각 쿼리에 대해 가장 유사한 문서 찾기\n",
    "for query in queries:\n",
    "    most_similar_doc, similarity = find_most_similar(\n",
    "        query, \n",
    "        document_embeddings_openai, \n",
    "        embeddings_model=embeddings_openai\n",
    "        )\n",
    "    print(f\"쿼리: {query}\")\n",
    "    print(f\"가장 유사한 문서: {most_similar_doc}\")\n",
    "    print(f\"유사도: {similarity:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c841a4",
   "metadata": {},
   "source": [
    "### 2. **Huggingface**\n",
    "\n",
    "- LangChain에서 오픈소스 기반의 대표적인 임베딩 모델\n",
    "\n",
    "- 주요 특징:\n",
    "    1. 로컬 환경에서 실행 가능\n",
    "    2. 다양한 사전학습 모델 지원\n",
    "    3. 커스텀 모델 학습 및 적용 가능\n",
    "    4. 무료 사용 가능 (API 비용 없음)\n",
    "\n",
    "- 사용시 주의사항:\n",
    "    1. 로컬 컴퓨팅 자원 필요 (CPU/GPU)\n",
    "    2. 초기 모델 다운로드 시간 소요\n",
    "    3. 메모리 사용량 고려 필요\n",
    "    4. transformers 라이브러리 설치 필요\n",
    "\n",
    "- 대표적인 임베딩 모델:\n",
    "    ```\n",
    "    모델                            차원      언어             특징      \n",
    "    all-MiniLM-L6-v2               384     다국어     빠른 속도, 적은 메모리\n",
    "    all-mpnet-base-v2              768     다국어     높은 성능, 중간 크기\n",
    "    multilingual-e5-large         1024     다국어     최고 성능, 큰 메모리\n",
    "    ```\n",
    "\n",
    "- 임베딩 벡터 특성:\n",
    "    1. 모델별로 다양한 차원 제공 (128 ~ 1024)\n",
    "    2. sentence-transformers 기반 구현\n",
    "    3. BERT 계열 모델 구조 사용\n",
    "    4. 코사인 유사도 기반 검색 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484e59a6",
   "metadata": {},
   "source": [
    "`(1) embedding 모델`\n",
    "\n",
    "- langchain_huggingface 설치 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6bae91c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings  \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Hugging Face의 임베딩 모델 생성\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m embeddings_bgem3 = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBAAI/bge-m3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# 사용할 모델 이름 - BAAI BGE-m3 모델 (한국어 성능 우수)\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# model_kwargs={'device': 'cuda'}  # GPU 사용시\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# model_kwargs={'device': 'mps'}   # Mac M1 사용시\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 임베딩 객체 출력\u001b[39;00m\n\u001b[32m     11\u001b[39m embeddings_bgem3\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/langchain_huggingface/embeddings/huggingface.py:94\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     92\u001b[39m     model_cls = sentence_transformers.SentenceTransformer\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28mself\u001b[39m._client = \u001b[43mmodel_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:309\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    300\u001b[39m         model_name_or_path = __MODEL_HUB_ORGANIZATION__ + \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m + model_name_or_path\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[32m    303\u001b[39m     model_name_or_path,\n\u001b[32m    304\u001b[39m     token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m     local_files_only=local_files_only,\n\u001b[32m    308\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     modules, \u001b[38;5;28mself\u001b[39m.module_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    321\u001b[39m     modules = \u001b[38;5;28mself\u001b[39m._load_auto_model(\n\u001b[32m    322\u001b[39m         model_name_or_path,\n\u001b[32m    323\u001b[39m         token=token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m         config_kwargs=config_kwargs,\n\u001b[32m    331\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:1808\u001b[39m, in \u001b[36mSentenceTransformer._load_sbert_model\u001b[39m\u001b[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[39m\n\u001b[32m   1805\u001b[39m \u001b[38;5;66;03m# Try to initialize the module with a lot of kwargs, but only if the module supports them\u001b[39;00m\n\u001b[32m   1806\u001b[39m \u001b[38;5;66;03m# Otherwise we fall back to the load method\u001b[39;00m\n\u001b[32m   1807\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1808\u001b[39m     module = \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1809\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1810\u001b[39m     module = module_class.load(model_name_or_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/sentence_transformers/models/Transformer.py:81\u001b[39m, in \u001b[36mTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[39m\n\u001b[32m     78\u001b[39m     config_args = {}\n\u001b[32m     80\u001b[39m config, is_peft_model = \u001b[38;5;28mself\u001b[39m._load_config(model_name_or_path, cache_dir, backend, config_args)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_peft_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n\u001b[32m     84\u001b[39m     tokenizer_args[\u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m] = max_seq_length\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/sentence_transformers/models/Transformer.py:181\u001b[39m, in \u001b[36mTransformer._load_model\u001b[39m\u001b[34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001b[39m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mself\u001b[39m._load_mt5_model(model_name_or_path, config, cache_dir, **model_args)\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[38;5;28mself\u001b[39m.auto_model = \u001b[43mAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_peft_model:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28mself\u001b[39m._load_peft_model(model_name_or_path, config, cache_dir, **model_args, **adapter_only_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py:600\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    599\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    604\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    605\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    606\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:311\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    309\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    313\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:4674\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4664\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4665\u001b[39m     gguf_file\n\u001b[32m   4666\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4667\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   4668\u001b[39m ):\n\u001b[32m   4669\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4670\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4671\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4672\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4674\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4676\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4680\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4681\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4687\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4692\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4694\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4695\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:1166\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n\u001b[32m   1163\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1164\u001b[39m         \u001b[38;5;66;03m# This repo has no safetensors file of any kind, we switch to PyTorch.\u001b[39;00m\n\u001b[32m   1165\u001b[39m         filename = _add_variant(WEIGHTS_NAME, variant)\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         resolved_archive_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcached_file_kwargs\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename == _add_variant(WEIGHTS_NAME, variant):\n\u001b[32m   1170\u001b[39m     \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n\u001b[32m   1171\u001b[39m     resolved_archive_file = cached_file(\n\u001b[32m   1172\u001b[39m         pretrained_model_name_or_path,\n\u001b[32m   1173\u001b[39m         _add_variant(WEIGHTS_INDEX_NAME, variant),\n\u001b[32m   1174\u001b[39m         **cached_file_kwargs,\n\u001b[32m   1175\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/transformers/utils/hub.py:312\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    255\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    256\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    257\u001b[39m     **kwargs,\n\u001b[32m    258\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    259\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    261\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/transformers/utils/hub.py:470\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    468\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    469\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    485\u001b[39m         snapshot_download(\n\u001b[32m    486\u001b[39m             path_or_repo_id,\n\u001b[32m    487\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    496\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    497\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:1008\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    989\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    990\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1005\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1006\u001b[39m     )\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:1161\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1158\u001b[39m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[32m   1160\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1161\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1173\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1174\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:1725\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1718\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1719\u001b[39m             logger.warning(\n\u001b[32m   1720\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo, but the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhf_xet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m package is not installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1721\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFalling back to regular HTTP download. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1722\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1723\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1725\u001b[39m         \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1726\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1728\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1729\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1730\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1731\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1732\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1734\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1735\u001b[39m _chmod_and_move(incomplete_path, destination_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:494\u001b[39m, in \u001b[36mhttp_get\u001b[39m\u001b[34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[39m\n\u001b[32m    492\u001b[39m new_resume_size = resume_size\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[32m    496\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/urllib3/response.py:1091\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1094\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/urllib3/response.py:980\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    978\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/urllib3/response.py:904\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    901\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    906\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/ms-ai-edu/ktds-llm/.venv/lib/python3.13/site-packages/urllib3/response.py:887\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings  \n",
    "\n",
    "# Hugging Face의 임베딩 모델 생성\n",
    "embeddings_bgem3 = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",          # 사용할 모델 이름 - BAAI BGE-m3 모델 (한국어 성능 우수)\n",
    "    # model_kwargs={'device': 'cuda'}  # GPU 사용시\n",
    "    # model_kwargs={'device': 'mps'}   # Mac M1 사용시\n",
    ")\n",
    "\n",
    "# 임베딩 객체 출력\n",
    "embeddings_bgem3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a5304f",
   "metadata": {},
   "source": [
    "`(2) embed_documents 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3645498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 임베딩\n",
    "document_embeddings_bgem3 = embeddings_bgem3.embed_documents(documents)\n",
    "\n",
    "# 임베딩 결과 출력\n",
    "print(f\"임베딩 벡터의 개수: {len(document_embeddings_bgem3)}\")\n",
    "print(f\"임베딩 벡터의 차원: {len(document_embeddings_bgem3[0])}\")\n",
    "print(document_embeddings_bgem3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447c8889",
   "metadata": {},
   "source": [
    "`(3) embed_query 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc1b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_query = embeddings_bgem3.embed_query(\"인공지능이란 무엇인가요?\")\n",
    "\n",
    "# 쿼리 임베딩 결과 출력\n",
    "print(f\"쿼리 임베딩 벡터의 차원: {len(embedded_query)}\")\n",
    "print(embedded_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62990788",
   "metadata": {},
   "source": [
    "`(4) 유사도 기반 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 쿼리\n",
    "queries = [\n",
    "    \"인공지능이란 무엇인가요?\",\n",
    "    \"딥러닝과 머신러닝의 관계는 어떻게 되나요?\",\n",
    "    \"컴퓨터가 이미지를 이해하는 방법은?\"\n",
    "]\n",
    "\n",
    "# 각 쿼리에 대해 가장 유사한 문서 찾기\n",
    "for query in queries:\n",
    "    most_similar_doc, similarity = find_most_similar(query, document_embeddings_bgem3, embeddings_model=embeddings_bgem3) \n",
    "    print(f\"쿼리: {query}\")\n",
    "    print(f\"가장 유사한 문서: {most_similar_doc}\")\n",
    "    print(f\"유사도: {similarity:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aeea6b",
   "metadata": {},
   "source": [
    "### 3. **Ollama**\n",
    "\n",
    "- LangChain에서 로컬 실행에 최적화된 경량 임베딩 모델\n",
    "\n",
    "- 주요 특징:\n",
    "    1. 완전한 로컬 실행 환경 제공\n",
    "    2. 빠른 추론 속도\n",
    "    3. 간단한 설치 및 실행 과정\n",
    "    4. Docker 기반 손쉬운 배포\n",
    "\n",
    "- 사용시 주의사항:\n",
    "    1. Ollama 서버 실행 필요\n",
    "    2. 모델별 시스템 요구사항 확인\n",
    "    3. API 엔드포인트 설정 필요\n",
    "    4. 동시 요청 처리량 고려\n",
    "\n",
    "- 대표적인 임베딩 모델:\n",
    "    ```\n",
    "    모델                차원       언어        특징\n",
    "    llama2              4096      영어       범용성 높은 기본 모델\n",
    "    nomic-embed-text    768       영어       경량화된 고성능 모델\n",
    "    codellama          2048       다국어     코드 특화 임베딩\n",
    "    ```\n",
    "\n",
    "- 임베딩 벡터 특성:\n",
    "    1. 모델별 고정 차원 사용\n",
    "    2. 최적화된 양자화 지원\n",
    "    3. 배치 처리 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b36e5a",
   "metadata": {},
   "source": [
    "`(1) embedding 모델`\n",
    "\n",
    "- langchain_ollama 설치 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings \n",
    "\n",
    "# OllamaEmbeddings 모델 생성\n",
    "# embeddings_ollama = OllamaEmbeddings(\n",
    "#     model=\"nomic-embed-text\",          # 사용할 모델 이름\n",
    "#     base_url=\"http://localhost:11434\"  # Ollama 서버 주소\n",
    "# )\n",
    "embeddings_ollama = OllamaEmbeddings(model=\"bge-m3\")\n",
    "\n",
    "# 임베딩 객체 출력\n",
    "embeddings_ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b54cb",
   "metadata": {},
   "source": [
    "`(2) embed_documents 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 컬렉션\n",
    "documents = [\n",
    "    \"인공지능은 컴퓨터 과학의 한 분야입니다.\",\n",
    "    \"머신러닝은 인공지능의 하위 분야입니다.\",\n",
    "    \"딥러닝은 머신러닝의 한 종류입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.\",\n",
    "    \"컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 방법을 연구합니다.\"\n",
    "]\n",
    "\n",
    "# 문서 임베딩\n",
    "document_embeddings_ollama = embeddings_ollama.embed_documents(documents)\n",
    "\n",
    "# 임베딩 결과 출력\n",
    "print(f\"임베딩 벡터의 개수: {len(document_embeddings_ollama)}\")\n",
    "print(f\"임베딩 벡터의 차원: {len(document_embeddings_ollama[0])}\")\n",
    "print(document_embeddings_ollama[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e637cb4",
   "metadata": {},
   "source": [
    "`(3) embed_query 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54504e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_query = embeddings_ollama.embed_query(\"인공지능이란 무엇인가요?\")\n",
    "\n",
    "# 쿼리 임베딩 결과 출력\n",
    "print(f\"쿼리 임베딩 벡터의 차원: {len(embedded_query)}\")\n",
    "print(embedded_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88021a49",
   "metadata": {},
   "source": [
    "`(4) 유사도 기반 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a671a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 쿼리\n",
    "queries = [\n",
    "    \"인공지능이란 무엇인가요?\",\n",
    "    \"딥러닝과 머신러닝의 관계는 어떻게 되나요?\",\n",
    "    \"컴퓨터가 이미지를 이해하는 방법은?\"\n",
    "]\n",
    "\n",
    "# 각 쿼리에 대해 가장 유사한 문서 찾기\n",
    "for query in queries:\n",
    "    most_similar_doc, similarity = find_most_similar(query, document_embeddings_ollama, embeddings_model=embeddings_ollama) \n",
    "    print(f\"쿼리: {query}\")\n",
    "    print(f\"가장 유사한 문서: {most_similar_doc}\")\n",
    "    print(f\"유사도: {similarity:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8edee46",
   "metadata": {},
   "source": [
    "# 벡터 저장소 (Vector Store)\n",
    "\n",
    "- 개념:\n",
    "    - 벡터화된 데이터를 효율적으로 저장하고 검색하기 위한 특수 데이터베이스 시스템\n",
    "    - 텍스트나 이미지 등의 비정형 데이터를 고차원 벡터 공간에 매핑하여 저장\n",
    "    - 유사도 기반 검색을 통해 의미적으로 가까운 데이터를 빠르게 검색 가능 \n",
    "\n",
    "- LangChain의 벡터 저장소 종류:\n",
    "    - **Chroma**: 경량화된 임베딩 데이터베이스로 로컬 개발에 적합\n",
    "    - **FAISS**: Facebook AI가 개발한 고성능 유사도 검색 라이브러리\n",
    "    - **Pinecone**: 완전 관리형 벡터 데이터베이스 서비스\n",
    "    - Milvus: 분산 벡터 데이터베이스로 대규모 데이터 처리에 적합\n",
    "    - PostgreSQL: pgvector 확장을 통해 벡터 저장 및 검색 기능을 제공\n",
    "\n",
    "- 주요 기능:\n",
    "    - 벡터 색인화: 효율적인 검색을 위한 데이터 구조화를 수행\n",
    "    - 근접 이웃 검색: 주어진 쿼리와 가장 유사한 벡터들을 검색 \n",
    "    - 메타데이터 관리: 벡터와 관련된 부가 정보를 함께 저장하고 검색\n",
    "\n",
    "- 사용 사례:\n",
    "    - 시맨틱 문서 검색: 문서의 의미를 이해하여 검색\n",
    "    - 추천 시스템: 유사한 아이템을 추천\n",
    "    - 중복 데이터 감지: 유사한 콘텐츠를 검색 \n",
    "    - 질의응답 시스템: 관련 문서에서 답변을 생성하는데 필요한 근거를 검색 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8fed68",
   "metadata": {},
   "source": [
    "### **Chroma**\n",
    "\n",
    "- 사용자 편의성이 우수한 오픈소스 벡터 저장소\n",
    "- `langchain-chroma` 패키지 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7da6e",
   "metadata": {},
   "source": [
    "`(1) 벡터 저장소 초기화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebb3bea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 문서 개수: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 로더 초기화 (근로기준법 문서)\n",
    "pdf_loader = PyPDFLoader('./data/labor_law.pdf')\n",
    "\n",
    "# 동기 로딩\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')\n",
    "\n",
    "len(pdf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fffc0d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 수: 95\n",
      "각 청크의 길이: [620, 476, 473, 468, 99, 627, 459, 517, 358, 607, 478, 472, 517, 387, 631, 541, 501, 474, 204, 558, 463, 459, 535, 432, 583, 497, 488, 463, 209, 609, 477, 504, 459, 512, 612, 483, 491, 476, 168, 633, 501, 471, 502, 193, 655, 509, 488, 465, 472, 637, 508, 493, 331, 589, 481, 537, 545, 496, 89, 593, 448, 473, 511, 318, 660, 528, 536, 505, 204, 624, 522, 489, 509, 129, 595, 485, 542, 530, 630, 482, 493, 379, 573, 511, 467, 196, 557, 494, 570, 550, 151, 671, 574, 480, 274]\n",
      "법제처                                                            1                                    ... 제1장 총칙\n",
      " \n",
      "제1조(목적) 이 법은 헌법에 따라 근로조건의 기준을 정함으로써 근로자의 기본적 생활을 보장, 향상시키며 균형 있는\n",
      "국민경제의 발전을 꾀하는 것을 목적으로 한다.\n",
      "====================================================================================================\n",
      "제1조(목적) 이 법은 헌법에 따라 근로조건의 기준을 정함으로써 근로자의 기본적 생활을 보장, 향상시키며 균형 있는\n",
      "국민경제의 발전을 꾀하는 것을 목적으로 한다.\n",
      " \n",
      "제2조(정의)...임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n",
      "5. “임금”이란 사용자가 근로의 대가로 근로자에게 임금, 봉급, 그 밖에 어떠한 명칭으로든지 지급하는 모든 금품을\n",
      "말한다.\n",
      "====================================================================================================\n",
      "결된 계약을 말한다.\n",
      "5. “임금”이란 사용자가 근로의 대가로 근로자에게 임금, 봉급, 그 밖에 어떠한 명칭으로든지 지급하는 모든 금품을\n",
      "말한다.\n",
      "6. “평균임금”이란 이를 산정하...는 통상 근로자의 1주\n",
      "동안의 소정근로시간에 비하여 짧은 근로자를 말한다.\n",
      "② 제1항제6호에 따라 산출된 금액이 그 근로자의 통상임금보다 적으면 그 통상임금액을 평균임금으로 한다.\n",
      "====================================================================================================\n",
      "동안의 소정근로시간에 비하여 짧은 근로자를 말한다.\n",
      "② 제1항제6호에 따라 산출된 금액이 그 근로자의 통상임금보다 적으면 그 통상임금액을 평균임금으로 한다.\n",
      " \n",
      "제3조(근로조건의 ...을 이유로 근로조건에 대한 차별적 처우를 하지 못한다.\n",
      " \n",
      "제7조(강제 근로의 금지) 사용자는 폭행, 협박, 감금, 그 밖에 정신상 또는 신체상의 자유를 부당하게 구속하는 수단으로\n",
      "====================================================================================================\n",
      "제7조(강제 근로의 금지) 사용자는 폭행, 협박, 감금, 그 밖에 정신상 또는 신체상의 자유를 부당하게 구속하는 수단으로\n",
      "써 근로자의 자유의사에 어긋나는 근로를 강요하지 못한다....제7조(강제 근로의 금지) 사용자는 폭행, 협박, 감금, 그 밖에 정신상 또는 신체상의 자유를 부당하게 구속하는 수단으로\n",
      "써 근로자의 자유의사에 어긋나는 근로를 강요하지 못한다.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# TikToken 인코더를 사용하여 재귀적 텍스트 분할기 초기화 (토큰 수 기준 분할)\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", \n",
    "    chunk_size=500, \n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할\n",
    "chunks = text_splitter.split_documents(pdf_docs) \n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "\n",
    "# 각 청크의 시작 부분과 끝 부분 확인\n",
    "for chunk in chunks[:5]:\n",
    "    print(f\"{chunk.page_content[:100]}...{chunk.page_content[-100:]}\")\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa19c207",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_chroma'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_chroma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# OpenAI 임베딩 모델 생성\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_chroma'"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 생성\n",
    "embeddings_openai = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",  # 사용할 모델 이름)\n",
    ")\n",
    "\n",
    "# Chroma 벡터 저장소 생성하기\n",
    "chroma_db = Chroma.from_documents(  \n",
    "    documents=chunks,\n",
    "    embedding=embeddings_openai,    # OpenAI 임베딩 사용\n",
    "    collection_name=\"labor_law\",    # 컬렉션 이름\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_metadata = {'hnsw:space': 'cosine'}, # l2, ip, cosine 중에서 선택 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa705465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 개수 확인\n",
    "chroma_db._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368e198",
   "metadata": {},
   "source": [
    "`(2) 벡터 저장소 로드`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 저장된 벡터 저장소를 가져오기\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"labor_law\",\n",
    "    embedding_function=embeddings_openai,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 개수 확인\n",
    "chroma_db._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aefca3",
   "metadata": {},
   "source": [
    "`(3) 문서 검색`  \n",
    "- 유사도 검색\n",
    "    - 주어진 쿼리와 가장 유사한 문서를 반환\n",
    "    -  k=5는 상위 5개의 결과를 반환하도록 지정\n",
    "    - filter를 사용하여 특정 출처의 문서만 검색 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c36347",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"'탄력 근로에 대해서 설명해주세요\"\n",
    "results = chroma_db.similarity_search(\n",
    "    query,\n",
    "    k=5,\n",
    "    filter={\"source\": \"./data/labor_law.pdf\"}\n",
    ")\n",
    "\n",
    "print(\"유사도 검색 결과:\")\n",
    "for doc in results:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cfc931",
   "metadata": {},
   "source": [
    "- 유사도 점수가 포함된 검색\n",
    "    - 유사도 점수를 함께 반환\n",
    "    - 점수가 낮을수록 더 유사한 것을 의미 (거리 기준으로 점수가 산정되기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f05840",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"'탄력 근로에 대해서 설명해주세요\"\n",
    "results = chroma_db.similarity_search_with_score(\n",
    "    query,\n",
    "    k=5,\n",
    ")\n",
    "\n",
    "print(\"점수가 포함된 유사도 검색 결과:\\n\")\n",
    "for doc, score in results:\n",
    "    print(f\"- 점수: {score:.4f}\")\n",
    "    print(f\"  내용: {doc.page_content}\")\n",
    "    print(f\" 메타데이터: {doc.metadata}\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1114cf",
   "metadata": {},
   "source": [
    "# 벡터 저장소 기반 RAG 검색기 (Retriever)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd1b80",
   "metadata": {},
   "source": [
    "`(1) Top K`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978859b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 2},\n",
    ")\n",
    "\n",
    "query = \"탄력 근로에 대해서 설명해주세요\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"-{i}-\\n{doc.page_content}\\n[출처: {doc.metadata['source']}]\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ee428",
   "metadata": {},
   "source": [
    "`(2) 임계값 지정`\n",
    "- Similarity score threshold (기준 스코어 이상인 문서를 대상으로 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8987f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type='similarity_score_threshold',       # cosine 유사도\n",
    "    search_kwargs={'score_threshold': 0.3, 'k':5},  # 0.3 이상인 문서를 추출\n",
    ")\n",
    "\n",
    "query = \"탄력 근로에 대해서 설명해주세요\"\n",
    "\n",
    "# 쿼리와 유사한 문서 검색\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    score = cosine_similarity(\n",
    "        [embeddings_openai.embed_query(query)], \n",
    "        [embeddings_openai.embed_query(doc.page_content)]\n",
    "        )[0][0]\n",
    "    print(f\"-{i}-\\n{doc.page_content}\\n[유사도: {score}]\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d4655",
   "metadata": {},
   "source": [
    "`(3) MMR(Maximal Marginal Relevance) 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ccc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMR - 다양성 고려 (lambda_mult 작을수록 더 다양하게 추출)\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={\n",
    "        'k': 3,                 # 검색할 문서의 수\n",
    "        'fetch_k': 8,           # mmr 알고리즘에 전달할 문서의 수 (fetch_k > k)\n",
    "        'lambda_mult': 0.5,     # 다양성을 고려하는 정도 (1은 최소 다양성, 0은 최대 다양성을 의미. 기본값은 0.5)\n",
    "        },\n",
    ")\n",
    "\n",
    "\n",
    "query = \"탄력 근로에 대해서 설명해주세요\"\n",
    "\n",
    "# 쿼리와 유사한 문서 검색\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    score = cosine_similarity(\n",
    "        [embeddings_openai.embed_query(query)], \n",
    "        [embeddings_openai.embed_query(doc.page_content)]\n",
    "        )[0][0]\n",
    "    print(f\"-{i}-\\n{doc.page_content}\\n[유사도: {score}]\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc95823",
   "metadata": {},
   "source": [
    "# Naive RAG 구현 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d70691e",
   "metadata": {},
   "source": [
    "`(1) 벡터 저장소 로드`\n",
    "- `Chroma` 벡터 저장소를 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b684474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 생성\n",
    "embeddings_openai = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",  # 사용할 모델 이름\n",
    "    )\n",
    "\n",
    "# 저장된 벡터 저장소를 가져오기\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"labor_law\",\n",
    "    embedding_function=embeddings_openai,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "# 문서 개수 확인\n",
    "print(f\"저장된 문서 수: {chroma_db._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b2f7d",
   "metadata": {},
   "source": [
    "`(2) 검색기(Retriever) 초기화`\n",
    "\n",
    "- mmr 검색을 사용하는 Retriever 사용\n",
    "- 다양성을 높이는 설정을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmr 검색기 생성\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={\n",
    "        'k': 5,                  # 검색할 문서의 수\n",
    "        'fetch_k': 10,           # mmr 알고리즘에 전달할 문서의 수 (fetch_k > k)\n",
    "        'lambda_mult': 0.3,      # 다양성을 고려하는 정도 (1은 최소 다양성, 0은 최대 다양성을 의미. 기본값은 0.5)\n",
    "        },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36743877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 테스트 \n",
    "query = \"탄력 근로에 대해서 설명해주세요\"\n",
    "\n",
    "# 쿼리와 유사한 문서 검색\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"-{i}-\\n{doc.page_content}\\n[출처: {doc.metadata['source']}]\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024d5d9",
   "metadata": {},
   "source": [
    "`(3) RAG 프롬프트 구성`\n",
    "\n",
    "- 작성 기준: \n",
    "    - LangChain의 ChatPromptTemplate 클래스 사용\n",
    "    - 변수 처리는 {context}, {question} 형식 사용\n",
    "    - 답변은 한글로 출력되도록 프롬프트 작성\n",
    "    \n",
    "- 아래 템플릿 코드를 기반으로 다음 내용을 참고하여 작성합니다. \n",
    "\n",
    "    1. 프롬프트 구성요소:\n",
    "        - 작업 지침\n",
    "        - 컨텍스트 영역\n",
    "        - 질문 영역\n",
    "        - 답변 형식 가이드\n",
    "\n",
    "    2. 작업 지침:\n",
    "        - 컨텍스트 기반 답변 원칙\n",
    "        - 외부 지식 사용 제한\n",
    "        - 불확실성 처리 방법\n",
    "        - 답변 불가능한 경우의 처리 방법\n",
    "\n",
    "    3. 답변 형식:\n",
    "        - 핵심 답변 섹션\n",
    "        - 근거 제시 섹션\n",
    "        - 추가 설명 섹션 (필요시)\n",
    "\n",
    "    4. 제약사항 반영:\n",
    "        - 답변은 사실에 기반해야 함\n",
    "        - 추측이나 가정을 최소화해야 함\n",
    "        - 명확한 근거 제시가 필요함\n",
    "        - 구조화된 형태로 작성되어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 템플릿 (기본 예시)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context.\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\n",
    "[Question] \n",
    "{question}\n",
    "\n",
    "[Answer]\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 템플릿 출력\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 템플릿 (커스텀 예시)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"주어진 컨텍스트를 기반으로 질문에 답변하시오.\n",
    "\n",
    "[지침]\n",
    "- 컨텍스트에 있는 정보만을 사용하여 답변할 것\n",
    "- 외부 지식이나 정보를 사용하지 말 것\n",
    "- 컨텍스트에서 답을 찾을 수 없는 경우 \"주어진 정보만으로는 답변하기 어렵습니다.\"라고 응답할 것\n",
    "- 불확실한 경우 명확히 그 불확실성을 표현할 것\n",
    "- 답변은 논리적이고 구조화된 형태로 제공할 것\n",
    "- 답변은 한국어를 사용할 것 \n",
    "\n",
    "[컨텍스트]\n",
    "{context}\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[답변 형식]\n",
    "1. 핵심 답변: (질문에 대한 직접적인 답변)\n",
    "2. 근거: (컨텍스트에서 발견된 관련 정보)\n",
    "3. 추가 설명: (필요한 경우 부연 설명 제공)\n",
    "\n",
    "[답변]\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 템플릿 출력\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f5cf5",
   "metadata": {},
   "source": [
    "`(4) RAG 체인 구성`\n",
    "- LangChain의 LCEL 문법을 사용\n",
    "- 검색 결과를 프롬프트의 'context'로 전달하고,\n",
    "- 사용자가 입력한 질문을 그래도 프롬프트의 'question'에 전달\n",
    "- LLM 설정:\n",
    "    - ChatOpenAI 사용 ('gpt-4.1-mini' 모델)\n",
    "    - temperature: 답변의 일관성을 가져가는 설정값을 사용 \n",
    "    - 기타 필요한 설정 \n",
    "- 출력 파서: 문자열 부분만 출력되도록 구성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4121f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 설정\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "# 문서 포맷팅\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([f\"{doc.page_content}\" for doc in docs])\n",
    "\n",
    "# RAG 체인 생성\n",
    "rag_chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": retriever | format_docs, \n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 체인 실행\n",
    "query = \"탄력 근로에 대해서 설명해주세요\"\n",
    "output = rag_chain.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"답변:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a614b56a",
   "metadata": {},
   "source": [
    "![LangServe Screenshot](https://raw.githubusercontent.com/tsdata/image_files/main/202505/rag_screenshot_0001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca2de1",
   "metadata": {},
   "source": [
    "`(5) LangServe 서버 구성`\n",
    "- app/rag.py 파일을 생성하여 RAG 체인과 관련된 코드를 작성함.\n",
    "\n",
    "    ```python\n",
    "    # app/rag.py\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    from langchain_core.runnables import RunnablePassthrough\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    from langchain_chroma import Chroma\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "    # 환경변수 로드\n",
    "    load_dotenv()\n",
    "\n",
    "\n",
    "    ######################\n",
    "    #  RAG 체인 구성\n",
    "    ######################\n",
    "\n",
    "    # OpenAI 임베딩 모델 생성\n",
    "    embeddings_openai = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-small\",  # 사용할 모델 이름\n",
    "        )\n",
    "\n",
    "    # 저장된 벡터 저장소를 가져오기\n",
    "    chroma_db = Chroma(\n",
    "        collection_name=\"labor_law\",\n",
    "        embedding_function=embeddings_openai,\n",
    "        persist_directory=\"./chroma_db\",\n",
    "    )\n",
    "\n",
    "    print(\"Chroma DB loaded\")\n",
    "    print(chroma_db._collection.count())  # 벡터 저장소에 있는 문서 수 출력\n",
    "\n",
    "    # 검색기 초기화å\n",
    "    retriever = chroma_db.as_retriever(\n",
    "        search_type='mmr',\n",
    "        search_kwargs={\n",
    "            'k': 5,                  # 검색할 문서의 수\n",
    "            'fetch_k': 10,           # mmr 알고리즘에 전달할 문서의 수 (fetch_k > k)\n",
    "            'lambda_mult': 0.3,      # 다양성을 고려하는 정도 (1은 최소 다양성, 0은 최대 다양성을 의미. 기본값은 0.5)\n",
    "            },\n",
    "    )\n",
    "\n",
    "    # Prompt 템플릿 생성\n",
    "    template = \"\"\"주어진 컨텍스트를 기반으로 질문에 답변하시오.\n",
    "\n",
    "    [지침]\n",
    "    - 컨텍스트에 있는 정보만을 사용하여 답변할 것\n",
    "    - 외부 지식이나 정보를 사용하지 말 것\n",
    "    - 컨텍스트에서 답을 찾을 수 없는 경우 \"주어진 정보만으로는 답변하기 어렵습니다.\"라고 응답할 것\n",
    "    - 불확실한 경우 명확히 그 불확실성을 표현할 것\n",
    "    - 답변은 논리적이고 구조화된 형태로 제공할 것\n",
    "    - 답변은 한국어를 사용할 것 \n",
    "\n",
    "    [컨텍스트]\n",
    "    {context}\n",
    "\n",
    "    [질문]\n",
    "    {question}\n",
    "\n",
    "    [답변 형식]\n",
    "    1. 핵심 답변: (질문에 대한 직접적인 답변)\n",
    "    2. 근거: (컨텍스트에서 발견된 관련 정보)\n",
    "    3. 추가 설명: (필요한 경우 부연 설명 제공)\n",
    "\n",
    "    [답변]\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # LLM 설정\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    # 문서 포맷팅\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join([f\"{doc.page_content}\" for doc in docs])\n",
    "\n",
    "    # RAG 체인 생성\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    ```\n",
    "\n",
    "\n",
    "- server.py 파일에 새로운 엔드포인트를 추가하여 RAG 체인을 호출하도록 설정함.\n",
    "\n",
    "    ```python\n",
    "    # app/server.py\n",
    "    from fastapi import FastAPI\n",
    "    from dotenv import load_dotenv\n",
    "    from app.rag import rag_chain\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langserve import add_routes\n",
    "\n",
    "    # 환경변수 로드\n",
    "    load_dotenv()\n",
    "\n",
    "    # FastAPI 서버를 설정\n",
    "    app = FastAPI(\n",
    "        title=\"LangChain Server\",\n",
    "        version=\"1.0\",\n",
    "        description=\"Spin up a simple api server using Langchain's Runnable interfaces\",\n",
    "    )\n",
    "\n",
    "    # 라우팅 설정\n",
    "    add_routes(\n",
    "        app,\n",
    "        ChatOpenAI(model=\"gpt-4.1-mini\"),\n",
    "        path=\"/openai\",   # OpenAI 모델에 대한 경로\n",
    "    )\n",
    "\n",
    "    add_routes(\n",
    "        app,\n",
    "        rag_chain,\n",
    "        path=\"/rag\",  # RAG 체인에 대한 경로\n",
    "    )\n",
    "\n",
    "    # FastAPI 서버 실행\n",
    "    if __name__ == \"__main__\":\n",
    "        import uvicorn\n",
    "\n",
    "        uvicorn.run(app, host=\"localhost\", port=8000)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f4f28",
   "metadata": {},
   "source": [
    "![LangServe Screenshot](https://raw.githubusercontent.com/tsdata/image_files/main/202505/rag_screenshot_0002.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktds-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
